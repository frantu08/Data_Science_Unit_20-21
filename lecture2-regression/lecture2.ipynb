{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Based on the notebook provided by Marek Rei)\n",
    "\n",
    "Loading the necessary libraries and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "data = pd.read_csv('data/country-stats.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a Good Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try a very basic model: $y=x$  \n",
    "If $x$ and $y$ are very highly correlated and in the same range, then this can actually give a reasonable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(data[\"Estimated Control of Corruption (scale -2.5 to 2.5)\"], \n",
    "            data[\"Estimated Government Effectiveness (scale -2.5 to 2.5)\"])\n",
    "plt.title('Estimated Corruption vs Government Effectiveness')\n",
    "plt.xlabel(\"Estimated Control of Corruption\")\n",
    "plt.ylabel(\"Estimated Government Effectiveness\")\n",
    "x_sample = np.linspace(-2.5, 2.5, 100)\n",
    "y = x_sample\n",
    "plt.plot(x_sample, y, color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for most practical cases this is not true, with $x$ and $y$ varying along very different ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(data[\"Estimated Control of Corruption (scale -2.5 to 2.5)\"], \n",
    "            data[\"Urban Population (%)\"])\n",
    "plt.title('Estimated Corruption vs Urban Population')\n",
    "plt.xlabel(\"Estimated Control of Corruption\")\n",
    "plt.ylabel(\"Urban Population (%)\")\n",
    "x_sample = np.linspace(-2.5, 2.5, 100)\n",
    "y = x_sample\n",
    "plt.plot(x_sample, y, color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a slightly more flexible model: $y=ax$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data[\"Estimated Control of Corruption (scale -2.5 to 2.5)\"], \n",
    "            data[\"Urban Population (%)\"])\n",
    "plt.title('Estimated Corruption vs Urban Population')\n",
    "plt.xlabel(\"Estimated Control of Corruption\")\n",
    "plt.ylabel(\"Urban Population (%)\")\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "X = data[\"Estimated Control of Corruption (scale -2.5 to 2.5)\"].values.reshape(-1,1)\n",
    "Y = data[\"Urban Population (%)\"]\n",
    "model.fit(X, Y)\n",
    "\n",
    "x_sample = np.linspace(-2.5, 2.5, 100)\n",
    "plt.plot(x_sample, model.predict(x_sample.reshape(-1,1)), color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about $y = b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "plt.scatter(data[\"Estimated Control of Corruption (scale -2.5 to 2.5)\"], \n",
    "            data[\"Urban Population (%)\"])\n",
    "plt.title('Estimated Corruption vs Urban Population')\n",
    "plt.xlabel(\"Estimated Control of Corruption\")\n",
    "plt.ylabel(\"Urban Population (%)\")\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "X = np.zeros((len(data[\"Urban Population (%)\"]), 1), dtype=float)\n",
    "Y = data[\"Urban Population (%)\"]\n",
    "model.fit(X, Y)\n",
    "\n",
    "x_sample = np.linspace(-2.5, 2.5, 100)\n",
    "plt.plot(x_sample, model.predict(x_sample.reshape(-1,1)), color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting these together, we get the simple linear regression model: $y = ax + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "plt.scatter(data[\"Estimated Control of Corruption (scale -2.5 to 2.5)\"], \n",
    "            data[\"Urban Population (%)\"])\n",
    "plt.title('Estimated Corruption vs Urban Population')\n",
    "plt.xlabel(\"Estimated Control of Corruption\")\n",
    "plt.ylabel(\"Urban Population (%)\")\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "X = data[\"Estimated Control of Corruption (scale -2.5 to 2.5)\"].values.reshape(-1,1)\n",
    "Y = data[\"Urban Population (%)\"]\n",
    "model.fit(X, Y)\n",
    "\n",
    "x_sample = np.linspace(-2.5, 2.5, 100)\n",
    "plt.plot(x_sample, model.predict(x_sample.reshape(-1,1)), color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Linear Regression: Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a linear regression model predicting enrolment rate from GDP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define a helper function to visualise a line ($y = ax + b$) that has been fit to a dataset (X, Y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simple_linear_regression(X, Y, a, b, title, xlabel, ylabel):\n",
    "    plt.scatter(X, Y)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    x_sample = np.linspace(np.min(X), np.max(X), 100)\n",
    "    plt.plot(x_sample, x_sample*a + b, color='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A verbose version of gradient descent, iterating over epochs and each datapoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"GDP per Capita (PPP USD)\"].values\n",
    "Y = data[\"Enrolment Rate, Tertiary (%)\"].values\n",
    "\n",
    "a = 0.0\n",
    "b = 0.0\n",
    "learning_rate = 1e-11\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    update_a = 0.0\n",
    "    update_b = 0.0\n",
    "    error = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        y_predicted = a * X[i] + b\n",
    "        update_a += (y_predicted - Y[i])*X[i]\n",
    "        update_b += (y_predicted - Y[i])\n",
    "        error += np.square(y_predicted - Y[i])\n",
    "    a = a - learning_rate * update_a\n",
    "    b = b - learning_rate * update_b\n",
    "    rmse = np.sqrt(error / len(Y))\n",
    "    print(\"a: {:.4f}\\tb: {:.9f}\\tRMSE: {:.4f}\".format(a, b, rmse))\n",
    "    #print(f\"a: {round(a, 4)}\\tb: {round(b, 9)}\\tRMSE: {round(rmse, 4)}\")\n",
    "plot_simple_linear_regression(X, Y, a, b, \n",
    "                              \"GDP vs Enrolment Rate\", \n",
    "                              \"GDP per Capita (PPP USD)\", \n",
    "                              \"Enrolment Rate, Tertiary (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more compact version, using python vector operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"GDP per Capita (PPP USD)\"].values\n",
    "Y = data[\"Enrolment Rate, Tertiary (%)\"].values\n",
    "\n",
    "a = 0.0\n",
    "b = 0.0\n",
    "learning_rate = 1e-11\n",
    "\n",
    "for epoch in range(10):\n",
    "    y_predicted = a * X + b\n",
    "    a = a - learning_rate * ((y_predicted - Y)*X).sum()\n",
    "    b = b - learning_rate * (y_predicted - Y).sum()\n",
    "    rmse = np.sqrt(np.square(y_predicted - Y).mean())\n",
    "    print(\"RMSE: \" + str(rmse))\n",
    "\n",
    "plot_simple_linear_regression(X, Y, a, b, \n",
    "                              \"GDP vs Enrolment Rate\", \n",
    "                              \"GDP per Capita (PPP USD)\", \n",
    "                              \"Enrolment Rate, Tertiary (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Linear Regression: The Analytical Solution with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using scikit-learn to calculate the analytical least squares solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "X = data[\"GDP per Capita (PPP USD)\"].values.reshape(-1,1)\n",
    "Y = data[\"Enrolment Rate, Tertiary (%)\"]\n",
    "model.fit(X, Y)\n",
    "\n",
    "mse = np.square(Y - model.predict(X)).mean()\n",
    "print(\"RMSE: \" + str(np.sqrt(mse)))\n",
    "\n",
    "plt.scatter(data[\"GDP per Capita (PPP USD)\"], \n",
    "            data[\"Enrolment Rate, Tertiary (%)\"])\n",
    "plt.title('GDP vs Enrolment Rate')\n",
    "plt.xlabel(\"GDP per Capita (PPP USD)\")\n",
    "plt.ylabel(\"Enrolment Rate, Tertiary (%)\")\n",
    "\n",
    "x_sample = np.linspace(0, 80000, 100)\n",
    "plt.plot(x_sample, \n",
    "         model.predict(x_sample.reshape(-1,1)), \n",
    "         color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting enrolment rate using all the available variables in the dataset.  \n",
    "We have to exclude the country name (because it's text and we can only handle numerical features at the moment) and the enrolment rate itself (because using that would be cheating).\n",
    "\n",
    "We can't really visualize an 11-dimensional graph, so we'll still project onto the same GDP vs Enrolment Rate graph, but the predictions will be made based on all 11 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "X = data.copy().drop([\"Country Name\", \"Enrolment Rate, Tertiary (%)\"], axis=1)\n",
    "Y = data[\"Enrolment Rate, Tertiary (%)\"]\n",
    "\n",
    "model.fit(X, Y)\n",
    "\n",
    "mse = np.square(Y - model.predict(X)).mean()\n",
    "print(\"RMSE: \" + str(np.sqrt(mse)))\n",
    "\n",
    "plt.scatter(data[\"GDP per Capita (PPP USD)\"], \n",
    "            data[\"Enrolment Rate, Tertiary (%)\"])\n",
    "plt.title('GDP vs Enrolment Rate')\n",
    "plt.xlabel(\"GDP per Capita (PPP USD)\")\n",
    "plt.ylabel(\"Enrolment Rate, Tertiary (%)\")\n",
    "\n",
    "x_pred = data[\"GDP per Capita (PPP USD)\"]\n",
    "plt.plot(x_pred, model.predict(X), '.', color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go in and inspect each of the learned coefficients in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers=list(X)\n",
    "coefficients = []\n",
    "for i in range(len(headers)):\n",
    "    coefficients.append({\"Property\": headers[i], \n",
    "                         \"coefficient\": model.coef_[i]})\n",
    "pd.DataFrame(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While interesting, these values are not comparable, because the range of each of the input features is very different and this is reflected in the coefficients.  \n",
    "We can standardize the input features before model fitting, which will make the coefficients comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of applying standardization to features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pd.DataFrame(data, columns=[\"GDP per Capita (PPP USD)\"])\n",
    "Z_scaled = preprocessing.scale(Z)\n",
    "\n",
    "asd = pd.concat([Z, pd.DataFrame(Z_scaled)], axis=1)\n",
    "asd.columns = [\"Z\", \"Z_scaled\"]\n",
    "asd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply it to our features before fitting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "X = data.copy().drop([\"Country Name\", \"Enrolment Rate, Tertiary (%)\"], axis=1)\n",
    "X_scaled = preprocessing.scale(X)\n",
    "Y = data[\"Enrolment Rate, Tertiary (%)\"]\n",
    "model.fit(X_scaled, Y)\n",
    "\n",
    "mse = np.square(Y - model.predict(X_scaled)).mean()\n",
    "print(\"RMSE: \" + str(np.sqrt(mse)))\n",
    "\n",
    "plt.scatter(data[\"GDP per Capita (PPP USD)\"], \n",
    "            data[\"Enrolment Rate, Tertiary (%)\"])\n",
    "plt.title('GDP vs Enrolment Rate')\n",
    "plt.xlabel(\"GDP per Capita (PPP USD)\")\n",
    "plt.ylabel(\"Enrolment Rate, Tertiary (%)\")\n",
    "\n",
    "x_pred = data[\"GDP per Capita (PPP USD)\"]\n",
    "plt.plot(x_pred, model.predict(X_scaled), '.', color='orange')\n",
    "plt.show()\n",
    "\n",
    "headers=list(X)\n",
    "coefficients = []\n",
    "for i in range(len(headers)):\n",
    "    coefficients.append({\"Property\": headers[i], \"coefficient\": model.coef_[i]})\n",
    "pd.DataFrame(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take our existing input features and have them transformed into a series of polynomial features.  \n",
    "\n",
    "With degree 2, features $[a, b]$ would become $[1, a, b, a^2, ab, b^2]$.  \n",
    "Our original 11 features become 78 polynomial features that are able to capture pairwise feature interactions.\n",
    "\n",
    "The number of polynomial features can be estimated as follows:\n",
    "\n",
    "<center>\n",
    "$\\begin{aligned}\n",
    "\\frac{(n + d)!}{n! d!}\n",
    "\\end{aligned}$ \n",
    "</center>\n",
    "\n",
    "where $n$ is the original number of features, and $d$ is the polynomial degree. Thus, $\\frac{(11 + 2)!}{11! 2!} = 78$ here.\n",
    "\n",
    "Polynomial regression is a special case of multiple linear regression – as a statistical estimation problem it is linear, but because it uses polynomial features it is able to model non-linear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "X = data.copy().drop([\"Country Name\", \"Enrolment Rate, Tertiary (%)\"], axis=1)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "Y = data[\"Enrolment Rate, Tertiary (%)\"]\n",
    "model.fit(X_poly, Y)\n",
    "\n",
    "mse = np.square(Y - model.predict(X_poly)).mean()\n",
    "print(\"RMSE: \" + str(np.sqrt(mse)))\n",
    "\n",
    "\n",
    "plt.scatter(data[\"GDP per Capita (PPP USD)\"], \n",
    "            data[\"Enrolment Rate, Tertiary (%)\"])\n",
    "plt.title('GDP vs Enrolment Rate')\n",
    "plt.xlabel(\"GDP per Capita (PPP USD)\")\n",
    "plt.ylabel(\"Enrolment Rate, Tertiary (%)\")\n",
    "\n",
    "x_pred = data[\"GDP per Capita (PPP USD)\"]\n",
    "plt.plot(x_pred, model.predict(X_poly), '.', color='orange')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try 3rd degree polynomial features. Our original 11 features are transformed into 364 features ($\\frac{(11 + 3)!}{11! 3!} = 364$).\n",
    "\n",
    "The resulting model captures the dataset almost perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "X = data.copy().drop([\"Country Name\", \"Enrolment Rate, Tertiary (%)\"], axis=1)\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_poly = poly.fit_transform(X)\n",
    "print(X_poly.shape) #check the number of data points vs the number of features\n",
    "Y = data[\"Enrolment Rate, Tertiary (%)\"]\n",
    "model.fit(X_poly, Y)\n",
    "\n",
    "mse = np.square(Y - model.predict(X_poly)).mean()\n",
    "print(\"RMSE: \" + str(np.sqrt(mse)))\n",
    "\n",
    "plt.scatter(data[\"GDP per Capita (PPP USD)\"], \n",
    "            data[\"Enrolment Rate, Tertiary (%)\"])\n",
    "plt.title('GDP vs Enrolment Rate')\n",
    "plt.xlabel(\"GDP per Capita (PPP USD)\")\n",
    "plt.ylabel(\"Enrolment Rate, Tertiary (%)\")\n",
    "\n",
    "x_pred = data[\"GDP per Capita (PPP USD)\"]\n",
    "plt.plot(x_pred, model.predict(X_poly), '.', color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, this model captures the dataset too perfectly.  \n",
    "There are twice as many features ($364$) for each datapoint as there are datapoints in the whole dataset ($161$). Such a model often has the capacity to memorize the training data, but that doesn't mean it is able to properly capture the underlying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splits for Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try an experiment. We will split our available dataset into three parts: training, development and test set.  \n",
    "We can fit the model on the **training** data, validate its performance and select model hyperparameters using the **development** data, and then finally evaluate the model using the **test** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a function for fitting polynomial regression with different degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial_regression(X, Y, degree):\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    model.fit(X_poly, Y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define one more function, to help us evaluate and plot the output from trained polynomial models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gdp_vs_enrolment_rate(X, Y, degree, model):\n",
    "    plt.scatter(X[\"GDP per Capita (PPP USD)\"], Y)\n",
    "    plt.title('GDP vs Enrolment Rate')\n",
    "    plt.xlabel(\"GDP per Capita (PPP USD)\")\n",
    "    plt.ylabel(\"Enrolment Rate, Tertiary (%)\")\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    \n",
    "    mse = np.square(Y - model.predict(X_poly)).mean()\n",
    "    print(\"RMSE: \" + str(np.sqrt(mse)))\n",
    "    \n",
    "    x_pred = X[\"GDP per Capita (PPP USD)\"]\n",
    "    plt.plot(x_pred, model.predict(X_poly), '.', color='orange')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try training the 3rd degree polynomial model on the training set and testing also on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_polynomial_regression(X_train, y_train, degree=3)\n",
    "plot_gdp_vs_enrolment_rate(X_train, y_train, degree=3, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, still a perfect fit.  \n",
    "\n",
    "How about fitting the same model on the training set and then evaluating on the development set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = fit_polynomial_regression(X_train, y_train, degree=3)\n",
    "plot_gdp_vs_enrolment_rate(X_dev, y_dev, degree=3, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's no good. The predictions are all over the place.  \n",
    "This model perfectly memorizes the training set but is not able to predict anything correctly on the development set. This might be a sign of **overfitting**. Let's try a lower-order model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = fit_polynomial_regression(X_train, y_train, degree=2)\n",
    "plot_gdp_vs_enrolment_rate(X_dev, y_dev, degree=2, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually better. Now let's go all the way down to the first degree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fit_polynomial_regression(X_train, y_train, degree=1)\n",
    "plot_gdp_vs_enrolment_rate(X_dev, y_dev, degree=1, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is indeed the model that gives the smallest error on held-out data.\n",
    "\n",
    "If we had a much larger dataset, with thousands or tens of thousands of examples, then the model wouldn't be able to overfit to the training set so easily and the polynomial features might actually provide a benefit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, when we have much fewer features available, the polynomial model can help model the correct shape in the data. We can try polynomial regression with only one variable again: the GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_single = pd.DataFrame(data, columns=[\"GDP per Capita (PPP USD)\"])\n",
    "Y_single = data[\"Enrolment Rate, Tertiary (%)\"]\n",
    "\n",
    "X_train_single, X_test_single, y_train_single, y_test_single = train_test_split(X_single, \n",
    "                                                                                Y_single, \n",
    "                                                                                test_size=0.2, \n",
    "                                                                                random_state=1)\n",
    "X_train_single, X_dev_single, y_train_single, y_dev_single = train_test_split(X_train_single, \n",
    "                                                                              y_train_single, \n",
    "                                                                              test_size=0.2, \n",
    "                                                                              random_state=1)\n",
    "\n",
    "model = fit_polynomial_regression(X_train_single.values.reshape(-1,1), y_train_single, degree=3)\n",
    "plot_gdp_vs_enrolment_rate(X_train_single, y_train_single, degree=3, model=model)\n",
    "plot_gdp_vs_enrolment_rate(X_dev_single, y_dev_single, degree=3, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(data[\"GDP per Capita (PPP USD)\"], \n",
    "            data[\"Enrolment Rate, Tertiary (%)\"])\n",
    "plt.title('GDP vs Enrolment Rate')\n",
    "plt.xlabel(\"GDP per Capita (PPP USD)\")\n",
    "plt.ylabel(\"Enrolment Rate, Tertiary (%)\")\n",
    "\n",
    "countries = list(data[\"Country Name\"])\n",
    "for c in [\"UK\", \"USA\", \"South Korea\", \"Luxembourg\", \"Qatar\", \"Malawi\"]:\n",
    "    country_num = countries.index(c)\n",
    "    plt.annotate(countries[country_num], (data[\"GDP per Capita (PPP USD)\"][country_num], \n",
    "                                          data[\"Enrolment Rate, Tertiary (%)\"][country_num]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tertiary education numbers can be checked here: http://wdi.worldbank.org/table/2.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to tell that a model is overfitting?\n",
    "\n",
    "Take a look at how the RMSE on the training and the development sets change with the number of examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def plot_learning_curves(X_train, y_train, X_dev, y_dev, degree, ylim_range):\n",
    "    pipeline = Pipeline((\n",
    "                        (\"scaler\", MinMaxScaler()),\n",
    "                        (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "                        (\"model\", LinearRegression()),\n",
    "                        ))\n",
    "    train_errors = []\n",
    "    dev_errors = []\n",
    "    for m in range(1, len(X_train)):\n",
    "        pipeline.fit(X_train[:m], y_train[:m])\n",
    "        y_train_pred = pipeline.predict(X_train[:m])\n",
    "        y_dev_pred = pipeline.predict(X_dev)\n",
    "        train_errors.append(np.sqrt(mean_squared_error(y_train_pred, y_train[:m])))\n",
    "        dev_errors.append(np.sqrt(mean_squared_error(y_dev_pred, y_dev)))\n",
    "        #train_errors.append(np.sqrt(np.square(y_train[:m] - y_train_pred).mean()))\n",
    "        #dev_errors.append(np.sqrt(np.square(y_dev - y_dev_pred).mean()))                                  \n",
    "    #print(dev_errors)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.ylim(0, ylim_range)\n",
    "    ax.plot(train_errors, \"+-\", color='darkblue', linewidth=2, label=\"train\")\n",
    "    ax.plot(dev_errors, 'x-', color='darkorange', linewidth=2, label=\"dev\")\n",
    "    ax.legend(loc=\"upper right\", fontsize=14)\n",
    "    ax.set_xlabel('Training set size')\n",
    "    ax.set_ylabel('RMSE')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore what happens with the simple regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(X_train, y_train, X_dev, y_dev, 1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how even though the error reaches a plateau on the training data, it is never exactly zero, i.e. the model doesn't catpure the training data perfectly. This is because the data is not exactly linear and it is noisy. At the same time, the error on the deevelopment set keeps dropping with more examples until it approximates the error on the training set quite closely.\n",
    "\n",
    "Now what happens if you plot the errors of the polynomial model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(X_train, y_train, X_dev, y_dev, 3, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the error on the training data is around zero (the training data is modelled, or rather memorized, perfectly well), but the difference between the training and development data is significant (note the difference in scale of errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "- Ridge Regression cost function:\n",
    "\n",
    "<center>\n",
    "$\\begin{aligned}\n",
    "J(\\theta) = MSE(\\theta) + \\alpha \\frac{1}{2} \\sum_{i=1}^{n} \\theta_i^{2}\n",
    "\\end{aligned}$ \n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso Regression cost function:\n",
    "\n",
    "<center>\n",
    "$\\begin{aligned}\n",
    "J(\\theta) = MSE(\\theta) + \\alpha \\sum_{i=1}^{n} |\\theta_i |\n",
    "\\end{aligned}$ \n",
    "</center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Elastic Net:\n",
    "\n",
    "<center>\n",
    "$\\begin{aligned}\n",
    "J(\\theta) = MSE(\\theta) + r\\alpha \\sum_{i=1}^{n} |\\theta_i | + \\frac{1-r}{2}\\alpha\\sum_{i=1}^{n} \\theta_i^{2}\n",
    "\\end{aligned}$ \n",
    "</center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
