{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Session 4: Getting Started with Deep Learning Models in TensorFlow\n",
    "\n",
    "*This notebook is based on past years' notebooks by Marek Rei and Guy Emerson*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This practical will cover a few different network architectures and we will look at different components that are often used in neural networks in practice. It will also allow you to learn more about [`TensorFlow`](https://www.tensorflow.org), a popular open-source machine learning and deep learning library. I'd also recommend checking the `TensorFlow` documentation to learn more about the rich functionality of this toolkit.\n",
    "\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "In this practical you will learn about:\n",
    "- The basics of running `TensorFlow` \n",
    "- How to implement a feedforward neural network in Python\n",
    "- How to visualise your network architecture using `TensorBoard` and track changes \n",
    "- How to apply deep learning to both classification and regression tasks.\n",
    "\n",
    "**Additional references**: Aurelien Geron, *Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow*.\n",
    "\n",
    "Before we start, let's import the usual libraries as we did in previous practicals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np \n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import `TensorFlow` into our notebook. Note: `TensorFlow` v2 was released last year, and it mostly relies on `Keras` interpretative module fit on top of it. As a result, it is much more interpretable and user-friendly than v1, however if you want to better understand the inner workings of `TensorFlow` you are welcome to check the accompanying notebook [`DSPNP_practical4-TFv1.ipynb`](./DSPNP_practical4-TFv1.ipynb): even if you are using `TensorFlow2`, you can still switch to using v1 API, which is available as a submodule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.compat.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal TensorFlow Example\n",
    "\n",
    "In this example, we create a simple network that takes an input vector, multiplies it by a weight matrix, adds a weight vector, and returns the result.\n",
    "\n",
    "`tf.Variable` defines model parameters, which can be trained (as we will see shortly). Here, we initialise the matrix variable as a 3x3 matrix, with every entry as 1 (`tf.ones`). Meanwhile, we initialise the 3x1 vector variable with every entry as 0 (`tf.zeros`). `tf.linalg.matvec` multiplies a matrix and a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([12. 12. 12.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "weight_matrix = tf.Variable(tf.ones(shape=(3,3)))\n",
    "weight_vector = tf.Variable(tf.zeros(shape=(3,)))\n",
    "\n",
    "def affine_transformation(input_vector):\n",
    "    return tf.linalg.matvec(weight_matrix, input_vector) + weight_vector\n",
    "\n",
    "result = affine_transformation([2.,3.,7.])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following [reset function](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session) is often useful. It is necessary to reset the `TensorFlow` network from time to time: as we have many different small networks in one notebook and we don't want them interfering with each other, as a pre-emptive measure we will occasionally reset the computation graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Parameters\n",
    "\n",
    "This example shows how to optimise the parameters in your model.\n",
    "\n",
    "We first define a network that takes an input vector, multiplies it with a matrix (as defined above), and sums the elements of the resulting vector (using `tf.math.reduce_sum`). We then define a loss function as the square error. Given a specific input and output, we can calculate the loss of applying the network to the input.\n",
    "\n",
    "Next, we define an optimiser â€“ here, we are using *stochastic gradient descent* (*SGD*) with the learning rate $0.001$. We then use this optimiser to train this network for $10$ epochs, over this single training point. This optimises the output towards the target value $20$. Printing out the results, we can see that the output gradually moves towards the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(29.952, shape=(), dtype=float32)\ntf.Tensor(26.190144, shape=(), dtype=float32)\ntf.Tensor(23.850271, shape=(), dtype=float32)\ntf.Tensor(22.39487, shape=(), dtype=float32)\ntf.Tensor(21.489607, shape=(), dtype=float32)\ntf.Tensor(20.926535, shape=(), dtype=float32)\ntf.Tensor(20.576305, shape=(), dtype=float32)\ntf.Tensor(20.358461, shape=(), dtype=float32)\ntf.Tensor(20.222961, shape=(), dtype=float32)\ntf.Tensor(20.138683, shape=(), dtype=float32)\ntf.Tensor(20.086262, shape=(), dtype=float32)\ntf.Tensor(20.053656, shape=(), dtype=float32)\ntf.Tensor(20.033375, shape=(), dtype=float32)\ntf.Tensor(20.020758, shape=(), dtype=float32)\ntf.Tensor(20.01291, shape=(), dtype=float32)\ntf.Tensor(20.00803, shape=(), dtype=float32)\ntf.Tensor(20.004995, shape=(), dtype=float32)\ntf.Tensor(20.003109, shape=(), dtype=float32)\ntf.Tensor(20.001932, shape=(), dtype=float32)\ntf.Tensor(20.001202, shape=(), dtype=float32)\ntf.Tensor(20.000748, shape=(), dtype=float32)\ntf.Tensor(20.000465, shape=(), dtype=float32)\ntf.Tensor(20.000286, shape=(), dtype=float32)\ntf.Tensor(20.00018, shape=(), dtype=float32)\ntf.Tensor(20.000114, shape=(), dtype=float32)\ntf.Tensor(20.000069, shape=(), dtype=float32)\ntf.Tensor(20.000044, shape=(), dtype=float32)\ntf.Tensor(20.000027, shape=(), dtype=float32)\ntf.Tensor(20.000017, shape=(), dtype=float32)\ntf.Tensor(20.000011, shape=(), dtype=float32)\ntf.Tensor(20.000006, shape=(), dtype=float32)\ntf.Tensor(20.000002, shape=(), dtype=float32)\ntf.Tensor(20.000002, shape=(), dtype=float32)\ntf.Tensor(20.000002, shape=(), dtype=float32)\ntf.Tensor(20.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "weight_matrix = tf.Variable(tf.ones(shape=(3,3)))\n",
    "weight_vector = tf.Variable(tf.zeros(shape=(3,)))\n",
    "\n",
    "def network(input_vector):\n",
    "    return tf.math.reduce_sum(affine_transformation(input_vector))\n",
    "\n",
    "def loss_fn(predicted, gold):\n",
    "    return tf.square(predicted - gold)\n",
    "\n",
    "input = [2.,3.,7.]\n",
    "gold_output = 20\n",
    "\n",
    "def loss():\n",
    "    return loss_fn(network(input), gold_output)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "for epoch in range(35):\n",
    "    opt.minimize(loss, var_list=[weight_matrix, weight_vector])\n",
    "    print(network(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional**: Try changing the learning rate and the number of epochs. What results are you getting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initial result with lr = 1e-3 and #epoch = 10\n",
    "\n",
    "tf.Tensor(29.952, shape=(), dtype=float32)\n",
    "tf.Tensor(26.190144, shape=(), dtype=float32)\n",
    "tf.Tensor(23.850271, shape=(), dtype=float32)\n",
    "tf.Tensor(22.39487, shape=(), dtype=float32)\n",
    "tf.Tensor(21.489607, shape=(), dtype=float32)\n",
    "tf.Tensor(20.926535, shape=(), dtype=float32)\n",
    "tf.Tensor(20.576305, shape=(), dtype=float32)\n",
    "tf.Tensor(20.358461, shape=(), dtype=float32)\n",
    "tf.Tensor(20.222961, shape=(), dtype=float32)\n",
    "tf.Tensor(20.138683, shape=(), dtype=float32)\n",
    "\n",
    "- With lr = 1e-2 and 10 epoch\n",
    "tf.Tensor(-24.48, shape=(), dtype=float32)\n",
    "tf.Tensor(143.6544, shape=(), dtype=float32)\n",
    "tf.Tensor(-323.75922, shape=(), dtype=float32)\n",
    "tf.Tensor(975.6506, shape=(), dtype=float32)\n",
    "tf.Tensor(-2636.7085, shape=(), dtype=float32)\n",
    "tf.Tensor(7405.6504, shape=(), dtype=float32)\n",
    "tf.Tensor(-20512.11, shape=(), dtype=float32)\n",
    "tf.Tensor(57099.266, shape=(), dtype=float32)\n",
    "tf.Tensor(-158660.36, shape=(), dtype=float32)\n",
    "tf.Tensor(441151.38, shape=(), dtype=float32)\n",
    "\n",
    "-- Overshooting big time\n",
    "\n",
    "- Back to lr = 1e-3. Try 20 epochs\n",
    "\n",
    " last = tf.Tensor(20.001202, shape=(), dtype=float32) =  improvement\n",
    "\n",
    "-- 100 epochs = converting to 20 pretty early on \n",
    "\n",
    "-- 40 epoch = more than enough for converting\n",
    "\n",
    "-- 35 enough\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Layers\n",
    "\n",
    "For most cases, we don't actually need to create the trainable variables manually. Instead, the feedfoward layer is available as a pre-defined module.\n",
    "\n",
    "We can define a network as a sequence of operations, using [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). The first operation here is a dense feedforward layer (`tf.keras.layers.Dense`), which acts like the `affine_transfomation` function we defined earlier. The second operation sums the elements of the vector â€“ this isn't a standard operation, so we use `tf.keras.layers.Lambda` to allow a user-defined function.\n",
    "\n",
    "By default, the parameters in a layer (like [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) are initialised randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape=(3,)),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.reduce_sum(x, axis=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that such a model expects the input data to be given as a *minibatch* â€“ this means that the input tensor should have an extra index, which ranges over datapoints. In our case, instead of passing a 3-dimensional input vector, we have to pass an Nx3 matrix, where N is the number of datapoints. Here, we can apply the model to a single datapoint (a 1x3 matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-3.755041], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.predict(tf.constant([[2.,3.,7.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model defined in terms of layers, let's replace the manually created variables of the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([3.3954916], shape=(1,), dtype=float32)\ntf.Tensor([9.671996], shape=(1,), dtype=float32)\ntf.Tensor([13.575982], shape=(1,), dtype=float32)\ntf.Tensor([16.00426], shape=(1,), dtype=float32)\ntf.Tensor([17.51465], shape=(1,), dtype=float32)\ntf.Tensor([18.454113], shape=(1,), dtype=float32)\ntf.Tensor([19.03846], shape=(1,), dtype=float32)\ntf.Tensor([19.40192], shape=(1,), dtype=float32)\ntf.Tensor([19.627996], shape=(1,), dtype=float32)\ntf.Tensor([19.768614], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape=(3,)),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.reduce_sum(x, axis=1))\n",
    "])\n",
    "\n",
    "def loss_fn(predicted, gold):\n",
    "    return tf.square(predicted - gold)\n",
    "\n",
    "input = tf.constant([[2.,3.,7.]])\n",
    "gold_output = 20\n",
    "\n",
    "def loss():\n",
    "    return loss_fn(model(input), gold_output)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "for epoch in range(10):\n",
    "    opt.minimize(loss, var_list=model.trainable_variables)\n",
    "    print(model(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, for standard optimizers and loss functions, the `TensorFlow` API makes it even easier for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(18.102009, shape=(), dtype=float32)\ntf.Tensor(18.819447, shape=(), dtype=float32)\ntf.Tensor(19.265697, shape=(), dtype=float32)\ntf.Tensor(19.543262, shape=(), dtype=float32)\ntf.Tensor(19.715912, shape=(), dtype=float32)\ntf.Tensor(19.823296, shape=(), dtype=float32)\ntf.Tensor(19.89009, shape=(), dtype=float32)\ntf.Tensor(19.931637, shape=(), dtype=float32)\ntf.Tensor(19.957478, shape=(), dtype=float32)\ntf.Tensor(19.973553, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape=(3,)),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.reduce_sum(x))\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3), # alternatively, optimizer=`sgd`\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "input = tf.constant([[2.,3.,7.]])\n",
    "gold_output = tf.constant([[20.]])\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train_on_batch(input, gold_output)\n",
    "    print(model(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "\n",
    "As you saw in the previous lectures, activation functions are what gives neural networks their power to model non-linear patterns in the data. After applying an affine transformation, we then apply a non-linear activation function to each element. There are a number of different activation functions to choose from.\n",
    "\n",
    "The [sigmoid function](https://en.wikipedia.org/wiki/Logistic_function), also known as the logistic function, is the most classic non-linear activation. It transforms the value to a range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.keras.layers.Dense(100, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In modern networks, the [tanh function](https://en.wikipedia.org/wiki/Hyperbolic_function) is used more often. It has more flexibility, as it transforms the input value to a range between -1 and 1, and can therefore output negative values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.keras.layers.Dense(100, activation='tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular one is the [Rectified Linear Unit](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) function, or the ReLU. This function acts as a linear function above zero, but restricts everything below zero to 0. By doing this it also introduces non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.keras.layers.Dense(100, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial linear property of the ReLU can help it converge faster on some tasks, although in practice tanh may be a more robust option.\n",
    "\n",
    "Finally, for classification tasks [softmax](https://en.wikipedia.org/wiki/Softmax_function) is an important activation function. Unlike the activation functions mentioned above, it isn't applied to each element separately. It converts a vector of scores into a probability distribution: after applying the softmax, all values are between 0 and 1, and together they sum to 1. Higher scores are assigned to higher probabilities, via the formula:\n",
    "\n",
    "\n",
    "$P(i) \\propto \\exp(x_i)$\n",
    "\n",
    "\n",
    "Or, more explicitly:\n",
    "\n",
    "$P(i) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n",
    "\n",
    "Notice how the value of the denominator depends on all other values.\n",
    "\n",
    "The softmax is often used in the output layer of a network performing classification, in order to predict a probability distribution over all the possible classes. For example, the following model takes a 20-dimensional input, maps it to a 50-dimensional hidden layer, then maps it to a distribution over 10 output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, input_shape=(20,), activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations and Useful Functions\n",
    "\n",
    "`TensorFlow` has corresponding versions of all the main operations you might want to use. This means you can add them into your computation graph and into your neural network. The most common operations are available in `tf`, and further operations are available in `tf.math`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.exp(x, name=None)>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "tf.abs # absolute value\n",
    "tf.negative # computes the negative value\n",
    "tf.sign # returns 1, 0 or -1 depending on the sign of the input\n",
    "tf.math.reciprocal # reciprocal 1/x\n",
    "tf.square # return input squared\n",
    "tf.round # return rounded value\n",
    "tf.sqrt # square root\n",
    "tf.math.rsqrt # reciprocal of square root\n",
    "tf.pow # power\n",
    "tf.exp # exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operations can be applied to scalar values, but also to vectors, matrices and higher-order tensors. In the latter case, they will be applied element-wise. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([-3.2  2.7], shape=(2,), dtype=float32)\ntf.Tensor([2.25      4.4099994], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.negative([3.2,-2.7]))\n",
    "print(tf.square([1.5,-2.1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful operations are performed over a whole vector/matrix tensor and return a single value (e.g., you saw `tf.reduce_sum` earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.argmin_v2(input, axis=None, output_type=tf.int64, name=None)>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "tf.reduce_sum # Add elements together\n",
    "tf.reduce_mean # Average over elements\n",
    "tf.reduce_min # Minimum value\n",
    "tf.reduce_max # Maximum value\n",
    "tf.argmax # Index of the largest value\n",
    "tf.argmin # Index of the smallest value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Learning Rates\n",
    "\n",
    "Above, we used stochastic gradient descent (SGD) to train our model. This uses a fixed learning rate to update the parameters. Several optimisation algorithms are based on SGD, but adaptively adjust the learning rate (usually for each parameter separately).\n",
    "\n",
    "Different adaptive learning rate strategies are also implemented in `TensorFlow` as functions. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "tf.keras.optimizers.SGD\n",
    "tf.keras.optimizers.Adadelta\n",
    "tf.keras.optimizers.Adam\n",
    "tf.keras.optimizers.RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in the differences between these strategies, [this blog post](http://ruder.io/optimizing-gradient-descent/) provides more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an XOR Function\n",
    "\n",
    "[XOR](https://en.wikipedia.org/wiki/XOR_gate) is the function that takes two binary values and returns 1 only if one of them is 1 and the other 0, while returning 0 if both of them have the same value. It can be a difficult function to learn and cannot be modelled with a linear model. But let's try anyway.\n",
    "\n",
    "Our dataset consists of all the possible different states that XOR can take:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_input = tf.constant([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "xor_output = tf.constant([0.0, 1.0, 1.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct a linear network and optimize it on this dataset, printing out the predictions at each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "after 10 epochs: [0.4314911  0.21679646 0.7357888  0.5210942 ]\n",
      "after 20 epochs: [0.45656076 0.33753362 0.6482736  0.52924645]\n",
      "after 30 epochs: [0.4685589  0.4020342  0.58808565 0.52156097]\n",
      "after 40 epochs: [0.47714671 0.44071558 0.5521115  0.5156803 ]\n",
      "after 50 epochs: [0.48338673 0.46404445 0.5307413  0.51139903]\n",
      "after 60 epochs: [0.48792288 0.4781378  0.51807165 0.5082866 ]\n",
      "after 70 epochs: [0.49122047 0.4866673  0.51057714 0.506024  ]\n",
      "after 80 epochs: [0.49361765 0.49184054 0.50615627 0.50437915]\n",
      "after 90 epochs: [0.49536034 0.49498624 0.50355756 0.5031835 ]\n",
      "after 100 epochs: [0.49662715 0.4969047  0.5020367  0.5023142 ]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "linear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(2,))\n",
    "])\n",
    "\n",
    "linear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "                     loss='mean_squared_error')\n",
    "\n",
    "for epoch in range(100):\n",
    "    linear_model.train_on_batch(xor_input, xor_output)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), linear_model(xor_input).numpy().reshape((4,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's not doing very well. Ideally, the predictions should be [0, 1, 1, 0], but in this case they are hovering around 0.5 for every input case.\n",
    "\n",
    "In order to improve this architecture, let's add some non-linear layers into our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "after 10 epochs: [0.45989323 0.43093646 0.5608539  0.4981238 ]\n",
      "after 20 epochs: [0.44220766 0.4436216  0.5664791  0.4958412 ]\n",
      "after 30 epochs: [0.42046416 0.4651907  0.5780684  0.4755422 ]\n",
      "after 40 epochs: [0.3811382  0.5118334  0.60057974 0.44931892]\n",
      "after 50 epochs: [0.3169607  0.57953346 0.6369069  0.4177347 ]\n",
      "after 60 epochs: [0.24966076 0.65029657 0.683118   0.36941773]\n",
      "after 70 epochs: [0.1966033  0.7101349  0.7308061  0.31433743]\n",
      "after 80 epochs: [0.158757   0.75610703 0.77194    0.26597506]\n",
      "after 90 epochs: [0.13208759 0.79046917 0.80423    0.22808403]\n",
      "after 100 epochs: [0.11291733 0.8162875  0.8289151  0.19923615]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(5, input_shape=(2,), activation='tanh'), # note that these settings can be changed\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='mean_squared_error')\n",
    "\n",
    "for epoch in range(100):\n",
    "    nonlinear_model.train_on_batch(xor_input, xor_output)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), nonlinear_model(xor_input).numpy().reshape((4,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better. The values are much closer to [0, 1, 1, 0] than before, and they will continue improving if we train for longer. (Remember that the model is initialised randomly â€“ if you run it a few times, you will see that the results vary with each run. Check the [documentation](https://www.tensorflow.org/tutorials/keras/save_and_load) on how you can save and restore a particular model).\n",
    "\n",
    "We also had to increase the learning rate for this network. It would still be learning with a smaller learning rate, but it would be converging very slowly. As we discussed in the lectures, learning rate is a hyperparameter that can vary quite a bit depending on the network architecture and dataset.\n",
    "\n",
    "**Optional**: Try changing various settings in the current network, e.g. *width* (number of neurons per layer), *depth* (number of layers), *activation functions* applied to each layer, and number of *epochs*. What changes do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "after 100 epochs: [0.03405055 0.9807839  0.97118914 0.02849326]\n",
      "after 200 epochs: [0.0208869  0.9877085  0.98192626 0.01688921]\n",
      "after 300 epochs: [0.01615027 0.99028826 0.9858793  0.01283455]\n",
      "after 400 epochs: [0.01357406 0.99171394 0.98808396 0.01066193]\n",
      "after 500 epochs: [0.01190048 0.99266267 0.9895389  0.00927323]\n",
      "after 600 epochs: [0.01070145 0.99334526 0.9905808  0.0082871 ]\n",
      "after 700 epochs: [0.00979254 0.9938662  0.99137616 0.00754517]\n",
      "after 800 epochs: [0.00907442 0.9942793  0.99200195 0.00696218]\n",
      "after 900 epochs: [0.00848827 0.9946203  0.9925239  0.00649017]\n",
      "after 1000 epochs: [0.00799954 0.99490553 0.9929513  0.00609764]\n"
     ]
    }
   ],
   "source": [
    "# Mine\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(32, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(16, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(8, input_shape=(2,), activation='tanh'), # note that these settings can be changed\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='mean_squared_error')\n",
    "\n",
    "for epoch in range(1000):\n",
    "    nonlinear_model.train_on_batch(xor_input, xor_output)\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), nonlinear_model(xor_input).numpy().reshape((4,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.keras.layers.Dense(100, input_shape=(2,), activation='relu') - got after 100 epochs: [0.15288806 0.91357195 0.910642   0.06977707]\n",
    "\n",
    "- tf.keras.layers.Dense(100, input_shape=(2,), activation='sigmoid') got after 100 epochs: [0.7675986  0.7659911  0.74394864 0.74212164] or after 100 epochs: [0.2369608  0.24330732 0.2336308  0.2398197 ] = weird\n",
    "\n",
    "- with more layers \n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "   \n",
    "    tf.keras.layers.Dense(16, input_shape=(2,), activation='tanh'),\n",
    "   \n",
    "    tf.keras.layers.Dense(8, input_shape=(2,), activation='tanh'), # note that these settings can be changed\n",
    "   \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    " \n",
    "\n",
    " after 100 epochs: [0.07005394 0.90713346 0.90309864 0.0912008 ]\n",
    "\n",
    "\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Dense(16, input_shape=(2,), activation='tanh'),\n",
    "    \n",
    "    tf.keras.layers.Dense(8, input_shape=(2,), activation='relu'), # note that these settings can be changed\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "after 100 epochs: [0.0411101  0.9592626  0.96524894 0.04195771]\n",
    "\n",
    "\n",
    "- best I got with 1000 epoch\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Dense(16, input_shape=(2,), activation='relu'),\n",
    "    \n",
    "    tf.keras.layers.Dense(8, input_shape=(2,), activation='tanh'), # note that these settings can be changed\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "after 1000 epochs: [0.01317123 0.99075276 0.991938   0.0065771 ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Classification\n",
    "\n",
    "We can also do classification with `TensorFlow`. For this, we often use the softmax activation function described above, which predicts the probability for each of the possible classes.\n",
    "\n",
    "We also have to change the loss function, as squared error is not suitable for classification. A suitable loss function is [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy). Since the correct output has probability 1 for the correct class, and probability 0 for the rest, minimising cross entropy is the same as minimising the negative log probability of the correct class for each datapoint. In other words, by minimising cross entropy, we are trying to find the maximum likelihood model, which assigns high values for the correct label.\n",
    "\n",
    "We can change the XOR example above to perform classification instead. In this case, we are constructing a binary classifier â€“ choosing between the classes of 0 and 1. The output here prints the predicted probabilities of the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "after 10 epochs:\n[[0.5755808  0.42441922]\n [0.51878613 0.4812138 ]\n [0.22188988 0.7781101 ]\n [0.5690694  0.4309306 ]]\nafter 20 epochs:\n[[0.6481799  0.35182008]\n [0.3930721  0.60692793]\n [0.07570078 0.92429924]\n [0.5817306  0.41826934]]\nafter 30 epochs:\n[[0.76032287 0.23967713]\n [0.27142018 0.7285798 ]\n [0.03043336 0.96956664]\n [0.8030073  0.19699265]]\nafter 40 epochs:\n[[0.91551244 0.08448751]\n [0.09463698 0.90536296]\n [0.0310323  0.9689677 ]\n [0.93439513 0.0656049 ]]\nafter 50 epochs:\n[[0.9531057  0.04689433]\n [0.04946918 0.9505309 ]\n [0.02252371 0.9774763 ]\n [0.96838623 0.03161371]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "for epoch in range(50):\n",
    "    nonlinear_model.train_on_batch(xor_input, xor_output)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), nonlinear_model(xor_input).numpy(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert these probabilities into class predictions and also report some of the more familiar [evaluation metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics), e.g. *accuracy*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "After 10 epochs: 0 1 0 0\n",
      "1/1 - 0s - loss: 0.5911 - accuracy: 0.7500\n",
      "\n",
      "Accuracy: 0.75\n",
      "\n",
      "After 20 epochs: 0 1 1 0\n",
      "1/1 - 0s - loss: 0.5160 - accuracy: 1.0000\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "After 30 epochs: 0 1 1 0\n",
      "1/1 - 0s - loss: 0.4340 - accuracy: 1.0000\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "After 40 epochs: 0 1 1 0\n",
      "1/1 - 0s - loss: 0.3807 - accuracy: 1.0000\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "After 50 epochs: 0 1 1 0\n",
      "1/1 - 0s - loss: 0.3614 - accuracy: 1.0000\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])  \n",
    "\n",
    "for epoch in range(50):\n",
    "    nonlinear_model.train_on_batch(xor_input, xor_output)\n",
    "    predictions = nonlinear_model.predict(xor_input)\n",
    "    result = tf.argmax(predictions, axis=1)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('\\nAfter {} epochs:'.format(epoch+1), \" \".join([str(x) for x in result.numpy()]))\n",
    "        test_loss, test_acc = nonlinear_model.evaluate(xor_input, xor_output, verbose=2)\n",
    "        print('\\nAccuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see in this printout that the model starts off with incorrect predictions, but fairly soon learns to return the correct sequence of [0, 1, 1, 0].\n",
    "\n",
    "Finally, here is how you can print out the confusion matrix. Since we are looking into a simple case here and the predictions from above are quite accurate, there is not much to be learned from the confusion matrix at this point (but note that this functionality may come in handy later in your practical):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2 0]\n [0 2]]\n"
     ]
    }
   ],
   "source": [
    "conf_mx = tf.math.confusion_matrix(xor_output, result.numpy()).numpy()\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minibatching\n",
    "\n",
    "For the XOR data, there are only 4 datapoints. However, with realistic datasets, it is inefficient to train on the whole dataset at once, because this will require a lot of computation in order to make a single update step. \n",
    "\n",
    "Instead, we can train on a batch of data at a time. For example, here is how you can take batches of 2 datapoints for the XOR data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "after 10 epochs:\n",
      "[[0.6146366  0.38536337]\n",
      " [0.32704777 0.67295223]\n",
      " [0.14118719 0.8588128 ]\n",
      " [0.8864163  0.1135837 ]]\n",
      "after 20 epochs:\n",
      "[[0.85141915 0.14858085]\n",
      " [0.03759621 0.96240383]\n",
      " [0.02701439 0.9729856 ]\n",
      " [0.98371613 0.01628381]]\n",
      "after 30 epochs:\n",
      "[[0.92407423 0.0759258 ]\n",
      " [0.0157696  0.98423034]\n",
      " [0.01245207 0.9875479 ]\n",
      " [0.9922225  0.00777754]]\n",
      "after 40 epochs:\n",
      "[[0.9498043  0.05019573]\n",
      " [0.00977722 0.9902228 ]\n",
      " [0.0082536  0.9917464 ]\n",
      " [0.99536395 0.00463601]]\n",
      "after 50 epochs:\n",
      "[[0.96288854 0.03711141]\n",
      " [0.00697349 0.9930265 ]\n",
      " [0.00622556 0.9937744 ]\n",
      " [0.99687386 0.00312617]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "for epoch in range(50):\n",
    "    for i in range(0,len(xor_input),BATCH_SIZE):\n",
    "        input_batch = xor_input[i:i+BATCH_SIZE]\n",
    "        output_batch = xor_output[i:i+BATCH_SIZE]\n",
    "        nonlinear_model.train_on_batch(input_batch, output_batch)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), nonlinear_model(xor_input).numpy(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this kind of functionality is built into `TensorFlow`. The following code trains the model with the given batch size and number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.6983\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 496us/step - loss: 0.7185\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.9771\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 999us/step - loss: 0.6602\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 512us/step - loss: 0.9783\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.7468\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6661\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.6424\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.9845\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 499us/step - loss: 1.0566\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.7347\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.6960\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 498us/step - loss: 0.6933\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 980us/step - loss: 0.6932\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 985us/step - loss: 0.6931\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6931\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.0032\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.9895\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9899\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 996us/step - loss: 0.9893\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 498us/step - loss: 0.9895\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 991us/step - loss: 0.7029\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1.0098\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 995us/step - loss: 0.9898\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.7004\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 499us/step - loss: 1.0088\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.7115\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.6944\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 503us/step - loss: 0.6932\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.0027\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 499us/step - loss: 1.0485\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.7212\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6950\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 997us/step - loss: 0.6933\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.0026\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.9894\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 495us/step - loss: 0.7009\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 492us/step - loss: 0.9983\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.7081\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.6941\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1.0014\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.9894\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 500us/step - loss: 0.9898\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1.0367\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.7185\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1.0147\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 498us/step - loss: 0.9901\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.7001\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 499us/step - loss: 1.0087\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.7115\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6951\n",
      "final loss: 0.695073127746582\n",
      "final predictions:\n",
      "[[0.5310022  0.46899778]\n",
      " [0.5310022  0.46899778]\n",
      " [0.5310022  0.46899778]\n",
      " [0.5310022  0.46899778]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "nonlinear_model.fit(xor_input, xor_output, batch_size=2, epochs=50)\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(xor_input, xor_output))\n",
    "print('final predictions:', nonlinear_model.predict(xor_input), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "\n",
    "So far, you have been exploring the results using simple print out messages. However, neural networks can grow very large and complicated, and you may wish to visualise and explore various components along the way. Visualisation in this case is not only a useful method for reporting and sharing your results, but also a good way to inspect your network and debug it. \n",
    "\n",
    "[`TensorBoard`](https://www.tensorflow.org/tensorboard) provides you with all the needed visualisation functionality and allows you to:\n",
    "\n",
    "- track and visualise metrics such as loss and accuracy;\n",
    "- visualise the model graph (ops and layers);\n",
    "- view histograms of weights, biases, or other tensors as they change over time;\n",
    "- project embeddings to a lower dimensional space;\n",
    "- display images, text, and audio data;\n",
    "- profile TensorFlow programs;\n",
    "\n",
    "among other things. Moreover, you can run it in your browser or embed it directly into your notebook as the code below shows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you will likely be introducing changes into your network and rerunning your code, it's important to be able to distinguish between these different runs to track the changes. Every time you run a new model, it will be stored in log files and added to your `TensorBoard`, so a good way to distinguish between various models is to add a time stamp to each of them. Let's add this functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make sure you clean all the previous logs (e.g., if you've run this notebook before). You can clear any logs from previous runs by running `rm -rf ./logs/` from within your notebook folder in your terminal.\n",
    "\n",
    "Once this is done, let's train a network and store its details in the log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6669WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7930WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_begin` time: 0.0020s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.6528s). Check your callbacks.\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 0.7930 - val_loss: 0.7293\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.1100 - val_loss: 0.8371\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8793 - val_loss: 0.7183\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.7631 - val_loss: 0.7015\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.7424 - val_loss: 0.6861\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.4614 - val_loss: 0.7392\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8521 - val_loss: 0.6931\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1602 - val_loss: 0.7474\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.0201 - val_loss: 0.7013\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.8136 - val_loss: 0.6911\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.0423 - val_loss: 0.7274\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.8014 - val_loss: 0.6957\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0411 - val_loss: 0.7305\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7833 - val_loss: 0.6964\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7500 - val_loss: 0.6930\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7751 - val_loss: 0.6926\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0454 - val_loss: 0.7303\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7775 - val_loss: 0.6981\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0328 - val_loss: 0.7287\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9918 - val_loss: 0.7036\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7602 - val_loss: 0.6934\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7469 - val_loss: 0.6941\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0069 - val_loss: 0.7197\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9906 - val_loss: 0.7055\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0318 - val_loss: 0.7314\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7558 - val_loss: 0.6971\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.9982 - val_loss: 0.7149\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7603 - val_loss: 0.6936\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7343 - val_loss: 0.6932\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7266 - val_loss: 0.6930\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7208 - val_loss: 0.6935\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0107 - val_loss: 0.7189\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7426 - val_loss: 0.6937\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7149 - val_loss: 0.6931\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0083 - val_loss: 0.7212\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7228 - val_loss: 0.6955\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7064 - val_loss: 0.6937\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0092 - val_loss: 0.7215\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7449 - val_loss: 0.6957\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7062 - val_loss: 0.6936\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7028 - val_loss: 0.6934\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0020 - val_loss: 0.7184\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0478 - val_loss: 0.7370\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7604 - val_loss: 0.6952\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0134 - val_loss: 0.7242\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7269 - val_loss: 0.6943\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7210 - val_loss: 0.6931\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.0050 - val_loss: 0.7196\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.0493 - val_loss: 0.7376\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7394 - val_loss: 0.6969\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6969\n",
      "final loss: 0.6968719363212585\n",
      "final predictions:\n",
      "[[0.5454252  0.45457473]\n",
      " [0.54256004 0.45743993]\n",
      " [0.5431422  0.4568578 ]\n",
      " [0.54020566 0.4597943 ]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='tanh'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "nonlinear_model.fit(xor_input, xor_output, \n",
    "                    batch_size=2, epochs=50, \n",
    "                    validation_data=(xor_input, xor_output),\n",
    "                    callbacks=[tensorboard_callback])\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(xor_input, xor_output))\n",
    "print('final predictions:', nonlinear_model.predict(xor_input), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you can explore your model in `TensorBoard`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 3400), started 1:58:19 ago. (Use '!kill 3400' to kill it.)"
     },
     "metadata": {}
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit --host localhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore both the results (e.g., learning curves) under the `Scalars` tab and the network architecture itself under the `Graphs` tab. All visualisations are interactive â€“ note that you can scroll in on the network components in the `Graph` visualisation and double-click on the \"+\" sign in the upper right corner of any component to track operations, weights, etc.\n",
    "\n",
    "A brief overview of the dashboards from [`TensorBoard` documentation](https://www.tensorflow.org/tensorboard/get_started):\n",
    "\n",
    "- The `Scalars` dashboard shows how the loss and metrics change with every epoch. You can use it to also track training speed, learning rate, and other scalar values.\n",
    "- The `Graphs` dashboard helps you visualise your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly.\n",
    "- The `Distributions` and `Histograms` dashboards show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way.\n",
    "\n",
    "There are additional `TensorBoard` plugins, which are automatically enabled when you log other types of data (note, it is not applicable to this notebook, as you are not working with any other types of data here). For example, the Keras `TensorBoard` callback lets you log images and embeddings as well. You can see what other plugins are available in `TensorBoard` by clicking on the \"inactive\" dropdown towards the top right.\n",
    "\n",
    "\n",
    "# Keeping track of the history\n",
    "\n",
    "There are other ways to get more information and description of your model, which are useful when you introduce more complexity to the model and would like to keep track of the changes. We'll summarise them in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, here is how you can return the information on the networks' layers and their types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x17978c7a670>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x17901da3580>]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "nonlinear_model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is how you can get a concise summary of the network layers (note that the first dimension in the output shape column is specified as `None` â€“ this is to denote that this dimension is variable as it depends on the batch size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 10)                30        \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 22        \n=================================================================\nTotal params: 52\nTrainable params: 52\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nonlinear_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also plot tje model summary like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz 2.44.1/bin/'\n",
    "tf.keras.utils.plot_model(nonlinear_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a number of ways to extract (and store) the information on individual layers, as well as on weights and biases in the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'dense_1'"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "hidden1 = nonlinear_model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "nonlinear_model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.64844376, -0.5216976 ],\n",
       "       [-0.33111575, -0.6379927 ],\n",
       "       [ 0.23762882, -0.6461444 ],\n",
       "       [-0.7063906 , -0.29117098],\n",
       "       [-0.69072443, -0.16513067],\n",
       "       [ 0.27732825, -0.36772484],\n",
       "       [ 0.482199  , -0.69763535],\n",
       "       [ 0.5370552 , -0.19780695],\n",
       "       [-0.4398944 , -0.6286145 ],\n",
       "       [ 0.0842163 ,  0.3300665 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model and track the changes in the loss and accuracy on the training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                       metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7609 - accuracy: 0.2500 - val_loss: 0.7885 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.4270 - accuracy: 0.5000 - val_loss: 1.2168 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6811 - accuracy: 0.0000e+00 - val_loss: 0.7909 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.2337 - accuracy: 0.0000e+00 - val_loss: 0.7302 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7164 - accuracy: 0.5000 - val_loss: 0.6943 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6901 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6901 - accuracy: 0.7500 - val_loss: 0.6870 - val_accuracy: 0.7500\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.7500 - val_loss: 0.6850 - val_accuracy: 0.7500\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6851 - accuracy: 0.7500 - val_loss: 0.6804 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.0005 - accuracy: 0.2500 - val_loss: 0.7028 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.5000 - val_loss: 0.6746 - val_accuracy: 0.5000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6738 - accuracy: 0.5000 - val_loss: 0.6518 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6521 - accuracy: 0.5000 - val_loss: 0.6425 - val_accuracy: 0.7500\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6667 - accuracy: 0.5000 - val_loss: 0.6573 - val_accuracy: 0.7500\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6651 - accuracy: 0.7500 - val_loss: 0.6312 - val_accuracy: 0.7500\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6327 - accuracy: 0.7500 - val_loss: 0.5787 - val_accuracy: 0.7500\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5815 - accuracy: 0.7500 - val_loss: 0.6105 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6777 - accuracy: 0.5000 - val_loss: 0.5578 - val_accuracy: 0.7500\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8176 - accuracy: 0.2500 - val_loss: 0.6121 - val_accuracy: 0.7500\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6022 - accuracy: 0.7500 - val_loss: 0.5114 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5654 - accuracy: 0.7500 - val_loss: 0.5656 - val_accuracy: 0.7500\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5722 - accuracy: 0.7500 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6813 - accuracy: 0.7500 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5337 - accuracy: 0.7500 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7500 - val_loss: 0.4998 - val_accuracy: 0.7500\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7500 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.7500 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5162 - accuracy: 0.7500 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.7500 - val_loss: 0.4829 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6265 - accuracy: 0.2500 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6002 - accuracy: 0.7500 - val_loss: 0.4820 - val_accuracy: 0.7500\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7500 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7448 - accuracy: 0.2500 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5240 - accuracy: 0.7500 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5173 - accuracy: 0.7500 - val_loss: 0.4822 - val_accuracy: 0.7500\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6137 - accuracy: 0.7500 - val_loss: 0.4834 - val_accuracy: 0.7500\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.2500 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.7500 - val_loss: 0.4827 - val_accuracy: 0.7500\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6175 - accuracy: 0.7500 - val_loss: 0.4921 - val_accuracy: 0.7500\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5245 - accuracy: 0.7500 - val_loss: 0.4795 - val_accuracy: 0.7500\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5126 - accuracy: 0.7500 - val_loss: 0.4801 - val_accuracy: 0.7500\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5071 - accuracy: 0.7500 - val_loss: 0.4790 - val_accuracy: 0.7500\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6016 - accuracy: 0.7500 - val_loss: 0.4800 - val_accuracy: 0.7500\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6108 - accuracy: 0.7500 - val_loss: 0.4817 - val_accuracy: 0.7500\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6159 - accuracy: 0.7500 - val_loss: 0.4826 - val_accuracy: 0.7500\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6182 - accuracy: 0.7500 - val_loss: 0.4829 - val_accuracy: 0.7500\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5130 - accuracy: 0.7500 - val_loss: 0.4834 - val_accuracy: 0.7500\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6260 - accuracy: 0.2500 - val_loss: 0.4825 - val_accuracy: 0.7500\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5165 - accuracy: 0.7500 - val_loss: 0.4782 - val_accuracy: 0.7500\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.7500 - val_loss: 0.4801 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "history = nonlinear_model.fit(xor_input, xor_output, batch_size=2, epochs=50,\n",
    "                    validation_data=(xor_input, xor_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 50, 'steps': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the changes across all epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"306.677344pt\" version=\"1.1\" viewBox=\"0 0 483.703125 306.677344\" width=\"483.703125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-11-24T12:44:03.181830</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 306.677344 \r\nL 483.703125 306.677344 \r\nL 483.703125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 282.799219 \r\nL 476.503125 282.799219 \r\nL 476.503125 10.999219 \r\nL 30.103125 10.999219 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 50.394034 282.799219 \r\nL 50.394034 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mdba028918b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.394034\" xlink:href=\"#mdba028918b\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(47.212784 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 133.214071 282.799219 \r\nL 133.214071 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"133.214071\" xlink:href=\"#mdba028918b\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(126.851571 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 216.034108 282.799219 \r\nL 216.034108 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"216.034108\" xlink:href=\"#mdba028918b\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(209.671608 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 298.854145 282.799219 \r\nL 298.854145 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"298.854145\" xlink:href=\"#mdba028918b\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(292.491645 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 381.674183 282.799219 \r\nL 381.674183 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"381.674183\" xlink:href=\"#mdba028918b\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(375.311683 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 464.49422 282.799219 \r\nL 464.49422 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"464.49422\" xlink:href=\"#mdba028918b\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(458.13172 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 30.103125 282.799219 \r\nL 476.503125 282.799219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mf8571d802e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf8571d802e\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(7.2 286.598437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 30.103125 228.439219 \r\nL 476.503125 228.439219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf8571d802e\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(7.2 232.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 30.103125 174.079219 \r\nL 476.503125 174.079219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf8571d802e\" y=\"174.079219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.4 -->\r\n      <g transform=\"translate(7.2 177.878437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 30.103125 119.719219 \r\nL 476.503125 119.719219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf8571d802e\" y=\"119.719219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.6 -->\r\n      <g transform=\"translate(7.2 123.518437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 30.103125 65.359219 \r\nL 476.503125 65.359219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf8571d802e\" y=\"65.359219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.8 -->\r\n      <g transform=\"translate(7.2 69.158437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#p1f26e91176)\" d=\"M 30.103125 10.999219 \r\nL 476.503125 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf8571d802e\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_25\">\r\n    <path clip-path=\"url(#p1f26e91176)\" d=\"M 50.394034 75.992879 \r\nL 53.915758 -1 \r\nM 78.275035 -1 \r\nL 83.522049 88.084105 \r\nL 91.804053 94.349746 \r\nL 100.086056 95.238832 \r\nL 108.36806 95.072695 \r\nL 116.650064 96.598349 \r\nL 124.932067 10.860866 \r\nL 133.214071 94.561617 \r\nL 141.496075 99.661936 \r\nL 149.778079 105.570728 \r\nL 158.060082 101.602081 \r\nL 166.342086 102.024591 \r\nL 174.62409 110.827399 \r\nL 182.906093 124.757192 \r\nL 191.188097 98.607054 \r\nL 199.470101 60.580849 \r\nL 207.752105 119.118869 \r\nL 216.034108 129.11577 \r\nL 224.316112 127.27521 \r\nL 232.598116 97.611515 \r\nL 240.880119 137.744859 \r\nL 249.162123 138.604735 \r\nL 257.444127 142.384192 \r\nL 265.726131 142.205533 \r\nL 274.008134 142.494891 \r\nL 282.290138 144.289263 \r\nL 290.572142 112.514183 \r\nL 298.854145 119.664811 \r\nL 307.136149 143.680625 \r\nL 315.418153 80.349691 \r\nL 323.700157 140.372279 \r\nL 331.98216 142.184407 \r\nL 340.264164 116.00088 \r\nL 348.546168 112.298359 \r\nL 356.828171 141.47147 \r\nL 365.110175 114.949254 \r\nL 373.392179 140.244895 \r\nL 381.674183 143.474732 \r\nL 389.956186 144.964518 \r\nL 398.23819 119.28925 \r\nL 406.520194 116.785748 \r\nL 414.802197 115.392679 \r\nL 423.084201 114.773462 \r\nL 431.366205 143.363353 \r\nL 439.648208 112.665075 \r\nL 447.930212 142.414876 \r\nL 456.212216 143.828017 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_26\">\r\n    <path clip-path=\"url(#p1f26e91176)\" d=\"M 50.394034 214.849219 \r\nL 58.676038 146.899219 \r\nL 66.958042 282.799219 \r\nL 75.240045 282.799219 \r\nL 83.522049 146.899219 \r\nL 91.804053 146.899219 \r\nL 100.086056 78.949219 \r\nL 108.36806 78.949219 \r\nL 116.650064 78.949219 \r\nL 124.932067 214.849219 \r\nL 133.214071 146.899219 \r\nL 141.496075 146.899219 \r\nL 149.778079 146.899219 \r\nL 158.060082 146.899219 \r\nL 166.342086 78.949219 \r\nL 174.62409 78.949219 \r\nL 182.906093 78.949219 \r\nL 191.188097 146.899219 \r\nL 199.470101 214.849219 \r\nL 207.752105 78.949219 \r\nL 216.034108 78.949219 \r\nL 224.316112 78.949219 \r\nL 232.598116 78.949219 \r\nL 240.880119 78.949219 \r\nL 249.162123 78.949219 \r\nL 257.444127 78.949219 \r\nL 265.726131 78.949219 \r\nL 274.008134 78.949219 \r\nL 282.290138 78.949219 \r\nL 290.572142 214.849219 \r\nL 298.854145 78.949219 \r\nL 307.136149 78.949219 \r\nL 315.418153 214.849219 \r\nL 323.700157 78.949219 \r\nL 331.98216 78.949219 \r\nL 340.264164 78.949219 \r\nL 348.546168 214.849219 \r\nL 356.828171 78.949219 \r\nL 365.110175 78.949219 \r\nL 373.392179 78.949219 \r\nL 381.674183 78.949219 \r\nL 389.956186 78.949219 \r\nL 398.23819 78.949219 \r\nL 406.520194 78.949219 \r\nL 414.802197 78.949219 \r\nL 423.084201 78.949219 \r\nL 431.366205 78.949219 \r\nL 439.648208 214.849219 \r\nL 447.930212 78.949219 \r\nL 456.212216 78.949219 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_27\">\r\n    <path clip-path=\"url(#p1f26e91176)\" d=\"M 50.394034 68.490635 \r\nL 55.337535 -1 \r\nM 62.033536 -1 \r\nL 66.958042 67.831953 \r\nL 75.240045 84.333858 \r\nL 83.522049 94.094118 \r\nL 91.804053 95.229111 \r\nL 100.086056 96.081422 \r\nL 108.36806 96.60444 \r\nL 116.650064 97.859415 \r\nL 124.932067 91.791259 \r\nL 133.214071 99.440928 \r\nL 141.496075 105.63877 \r\nL 149.778079 108.177638 \r\nL 158.060082 104.143978 \r\nL 166.342086 111.251205 \r\nL 174.62409 125.509448 \r\nL 182.906093 116.865471 \r\nL 191.188097 131.201233 \r\nL 199.470101 116.420263 \r\nL 207.752105 143.809678 \r\nL 216.034108 129.063637 \r\nL 224.316112 143.547116 \r\nL 232.598116 144.077343 \r\nL 240.880119 144.184267 \r\nL 249.162123 146.961494 \r\nL 257.444127 149.790732 \r\nL 265.726131 150.144544 \r\nL 274.008134 150.176507 \r\nL 282.290138 151.548297 \r\nL 290.572142 149.522718 \r\nL 298.854145 151.795736 \r\nL 307.136149 134.063497 \r\nL 315.418153 149.04008 \r\nL 323.700157 150.554053 \r\nL 331.98216 151.727037 \r\nL 340.264164 151.412455 \r\nL 348.546168 150.863224 \r\nL 356.828171 151.595124 \r\nL 365.110175 149.050707 \r\nL 373.392179 152.483335 \r\nL 381.674183 152.314785 \r\nL 389.956186 152.605876 \r\nL 398.23819 152.343857 \r\nL 406.520194 151.88466 \r\nL 414.802197 151.636193 \r\nL 423.084201 151.535061 \r\nL 431.366205 151.408008 \r\nL 439.648208 151.664357 \r\nL 447.930212 152.811121 \r\nL 456.212216 152.305801 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_28\">\r\n    <path clip-path=\"url(#p1f26e91176)\" d=\"M 50.394034 146.899219 \r\nL 58.676038 146.899219 \r\nL 66.958042 146.899219 \r\nL 75.240045 146.899219 \r\nL 83.522049 146.899219 \r\nL 91.804053 146.899219 \r\nL 100.086056 78.949219 \r\nL 108.36806 78.949219 \r\nL 116.650064 146.899219 \r\nL 124.932067 146.899219 \r\nL 133.214071 146.899219 \r\nL 141.496075 146.899219 \r\nL 149.778079 78.949219 \r\nL 158.060082 78.949219 \r\nL 166.342086 78.949219 \r\nL 174.62409 78.949219 \r\nL 182.906093 146.899219 \r\nL 191.188097 78.949219 \r\nL 199.470101 78.949219 \r\nL 207.752105 78.949219 \r\nL 216.034108 78.949219 \r\nL 224.316112 78.949219 \r\nL 232.598116 78.949219 \r\nL 240.880119 78.949219 \r\nL 249.162123 78.949219 \r\nL 257.444127 78.949219 \r\nL 265.726131 78.949219 \r\nL 274.008134 78.949219 \r\nL 282.290138 78.949219 \r\nL 290.572142 78.949219 \r\nL 298.854145 78.949219 \r\nL 307.136149 78.949219 \r\nL 315.418153 78.949219 \r\nL 323.700157 78.949219 \r\nL 331.98216 78.949219 \r\nL 340.264164 78.949219 \r\nL 348.546168 78.949219 \r\nL 356.828171 78.949219 \r\nL 365.110175 78.949219 \r\nL 373.392179 78.949219 \r\nL 381.674183 78.949219 \r\nL 389.956186 78.949219 \r\nL 398.23819 78.949219 \r\nL 406.520194 78.949219 \r\nL 414.802197 78.949219 \r\nL 423.084201 78.949219 \r\nL 431.366205 78.949219 \r\nL 439.648208 78.949219 \r\nL 447.930212 78.949219 \r\nL 456.212216 78.949219 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 282.799219 \r\nL 30.103125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 476.503125 282.799219 \r\nL 476.503125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 282.799219 \r\nL 476.503125 282.799219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 10.999219 \r\nL 476.503125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 372.559375 78.267969 \r\nL 469.503125 78.267969 \r\nQ 471.503125 78.267969 471.503125 76.267969 \r\nL 471.503125 17.999219 \r\nQ 471.503125 15.999219 469.503125 15.999219 \r\nL 372.559375 15.999219 \r\nQ 370.559375 15.999219 370.559375 17.999219 \r\nL 370.559375 76.267969 \r\nQ 370.559375 78.267969 372.559375 78.267969 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_29\">\r\n     <path d=\"M 374.559375 24.097656 \r\nL 394.559375 24.097656 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_30\"/>\r\n    <g id=\"text_13\">\r\n     <!-- loss -->\r\n     <g transform=\"translate(402.559375 27.597656)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_31\">\r\n     <path d=\"M 374.559375 38.775781 \r\nL 394.559375 38.775781 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_32\"/>\r\n    <g id=\"text_14\">\r\n     <!-- accuracy -->\r\n     <g transform=\"translate(402.559375 42.275781)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_33\">\r\n     <path d=\"M 374.559375 53.453906 \r\nL 394.559375 53.453906 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_34\"/>\r\n    <g id=\"text_15\">\r\n     <!-- val_loss -->\r\n     <g transform=\"translate(402.559375 56.953906)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 8.796875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nL 35.6875 0 \r\nL 23.484375 0 \r\nz\r\n\" id=\"DejaVuSans-118\"/>\r\n       <path d=\"M 50.984375 -16.609375 \r\nL 50.984375 -23.578125 \r\nL -0.984375 -23.578125 \r\nL -0.984375 -16.609375 \r\nz\r\n\" id=\"DejaVuSans-95\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_35\">\r\n     <path d=\"M 374.559375 68.410156 \r\nL 394.559375 68.410156 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_36\"/>\r\n    <g id=\"text_16\">\r\n     <!-- val_accuracy -->\r\n     <g transform=\"translate(402.559375 71.910156)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"259.521484\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"369.482422\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"432.861328\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"473.974609\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"535.253906\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"590.234375\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p1f26e91176\">\r\n   <rect height=\"271.8\" width=\"446.4\" x=\"30.103125\" y=\"10.999219\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case of regression\n",
    "\n",
    "Finally, you can address not only classification but also regression tasks with `TensorFlow`. Let's look at a short example here.\n",
    "\n",
    "In Practical 1 you have been using a custom version of the California housing dataset (refer to the Practical 1 to see what differences were introduced in the original data). The original version is [accessible via `sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html), and the code below shows how to access a dataset from `sklearn` (in fact, `sklearn` provides access to a number of useful ML datasets, so take a look at the [documentation](https://scikit-learn.org/stable/datasets/index.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let't split the dataset into training, validation, and test sets. Note that you can access the data from the dataset with `housing.data`, and the labels with `housing.target`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And scale the data using standardisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows to you how to implement a regression model using `TensorFlow`. It is quite similar to the code for classification with minor difference: the loss function that you use here is mean squared error, and the output is a single predicted value thus the dimensionality of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "  1/363 [..............................] - ETA: 0s - loss: 3.7219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "363/363 [==============================] - 0s 949us/step - loss: 1.6419 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 711us/step - loss: 0.7047 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 688us/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.5977 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.5706 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 730us/step - loss: 0.5472 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 736us/step - loss: 0.5288 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 727us/step - loss: 0.5130 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 731us/step - loss: 0.4992 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 678us/step - loss: 0.4875 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 636us/step - loss: 0.4777 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 706us/step - loss: 0.4688 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 765us/step - loss: 0.4615 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 757us/step - loss: 0.4547 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.4488 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 717us/step - loss: 0.4435 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 639us/step - loss: 0.4389 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.4347 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 670us/step - loss: 0.4306 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.4273 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 464us/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "reg_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "reg_model.compile(loss=\"mean_squared_error\", optimizer=tf.keras.optimizers.SGD(lr=1e-3))\n",
    "history = reg_model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = reg_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"252.317344pt\" version=\"1.1\" viewBox=\"0 0 372.103125 252.317344\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-11-24T12:44:10.320864</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 252.317344 \r\nL 372.103125 252.317344 \r\nL 372.103125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 228.439219 \r\nL 364.903125 228.439219 \r\nL 364.903125 10.999219 \r\nL 30.103125 10.999219 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 45.321307 228.439219 \r\nL 45.321307 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m8f2d756b00\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m8f2d756b00\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(37.369744 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 85.369154 228.439219 \r\nL 85.369154 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"85.369154\" xlink:href=\"#m8f2d756b00\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2.5 -->\r\n      <g transform=\"translate(77.417591 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 125.417001 228.439219 \r\nL 125.417001 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"125.417001\" xlink:href=\"#m8f2d756b00\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 5.0 -->\r\n      <g transform=\"translate(117.465438 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 165.464847 228.439219 \r\nL 165.464847 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"165.464847\" xlink:href=\"#m8f2d756b00\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 7.5 -->\r\n      <g transform=\"translate(157.513285 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 205.512694 228.439219 \r\nL 205.512694 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"205.512694\" xlink:href=\"#m8f2d756b00\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 10.0 -->\r\n      <g transform=\"translate(194.379882 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 245.560541 228.439219 \r\nL 245.560541 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"245.560541\" xlink:href=\"#m8f2d756b00\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 12.5 -->\r\n      <g transform=\"translate(234.427729 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 285.608388 228.439219 \r\nL 285.608388 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"285.608388\" xlink:href=\"#m8f2d756b00\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 15.0 -->\r\n      <g transform=\"translate(274.475576 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 325.656235 228.439219 \r\nL 325.656235 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"325.656235\" xlink:href=\"#m8f2d756b00\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 17.5 -->\r\n      <g transform=\"translate(314.523423 243.037656)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 30.103125 228.439219 \r\nL 364.903125 228.439219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mbbbc73eb53\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mbbbc73eb53\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(7.2 232.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 30.103125 184.951219 \r\nL 364.903125 184.951219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mbbbc73eb53\" y=\"184.951219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(7.2 188.750437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 30.103125 141.463219 \r\nL 364.903125 141.463219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mbbbc73eb53\" y=\"141.463219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.4 -->\r\n      <g transform=\"translate(7.2 145.262437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 30.103125 97.975219 \r\nL 364.903125 97.975219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mbbbc73eb53\" y=\"97.975219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.6 -->\r\n      <g transform=\"translate(7.2 101.774437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_25\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 30.103125 54.487219 \r\nL 364.903125 54.487219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mbbbc73eb53\" y=\"54.487219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.8 -->\r\n      <g transform=\"translate(7.2 58.286437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_27\">\r\n      <path clip-path=\"url(#p86dad68b03)\" d=\"M 30.103125 10.999219 \r\nL 364.903125 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_28\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mbbbc73eb53\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_29\">\r\n    <path clip-path=\"url(#p86dad68b03)\" d=\"M 55.349557 -1 \r\nL 61.340446 75.210017 \r\nL 77.359584 90.464396 \r\nL 93.378723 98.467425 \r\nL 109.397862 104.361662 \r\nL 125.417001 109.446105 \r\nL 141.436139 113.466211 \r\nL 157.455278 116.889852 \r\nL 173.474417 119.902233 \r\nL 189.493556 122.437385 \r\nL 205.512694 124.560699 \r\nL 221.531833 126.511458 \r\nL 237.550972 128.08849 \r\nL 253.570111 129.565442 \r\nL 269.589249 130.858498 \r\nL 285.608388 132.010959 \r\nL 301.627527 133.009716 \r\nL 317.646666 133.927477 \r\nL 333.665804 134.805741 \r\nL 349.684943 135.522148 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_30\">\r\n    <path clip-path=\"url(#p86dad68b03)\" d=\"M 45.321307 42.321024 \r\nL 61.340446 86.434323 \r\nL 77.359584 95.823069 \r\nL 93.378723 105.402436 \r\nL 109.397862 112.008758 \r\nL 125.417001 115.95626 \r\nL 141.436139 117.956289 \r\nL 157.455278 124.08498 \r\nL 173.474417 126.469317 \r\nL 189.493556 127.191278 \r\nL 205.512694 130.974513 \r\nL 221.531833 131.044746 \r\nL 237.550972 135.032276 \r\nL 253.570111 136.396906 \r\nL 269.589249 137.64692 \r\nL 285.608388 138.789914 \r\nL 301.627527 139.908581 \r\nL 317.646666 140.663824 \r\nL 333.665804 141.456763 \r\nL 349.684943 142.129364 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 228.439219 \r\nL 30.103125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 364.903125 228.439219 \r\nL 364.903125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 228.439219 \r\nL 364.903125 228.439219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 10.999219 \r\nL 364.903125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p86dad68b03\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"10.999219\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also explore model's predictions on some selected datapoints and compare them to the true values for these datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.3885664],\n",
       "       [1.6792021],\n",
       "       [3.1022797]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = reg_model.predict(X_new)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001])"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Classification of House Locations\n",
    "\n",
    "In the first practical, you used the California House Prices Dataset in order to predict the prices of the houses based on various properties about the houses. In this assignment, we will experiment with `TensorFlow` and train a model to predict the \"ocean proximity\" of a house.\n",
    "\n",
    "First, let's read in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>median_house_value</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41.0</td>\n      <td>880.0</td>\n      <td>129.0</td>\n      <td>322.0</td>\n      <td>126.0</td>\n      <td>8.3252</td>\n      <td>452600.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21.0</td>\n      <td>7099.0</td>\n      <td>1106.0</td>\n      <td>2401.0</td>\n      <td>1138.0</td>\n      <td>8.3014</td>\n      <td>358500.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1467.0</td>\n      <td>190.0</td>\n      <td>496.0</td>\n      <td>177.0</td>\n      <td>7.2574</td>\n      <td>352100.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1274.0</td>\n      <td>235.0</td>\n      <td>558.0</td>\n      <td>219.0</td>\n      <td>5.6431</td>\n      <td>341300.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52.0</td>\n      <td>1627.0</td>\n      <td>280.0</td>\n      <td>565.0</td>\n      <td>259.0</td>\n      <td>3.8462</td>\n      <td>342200.0</td>\n      <td>NEAR BAY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('housing/housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the ocean proximity column from the other features and convert the values to numerical IDs. Remember, the `ocean_proximity` column already contains discrete classes, so it is well-suited for the classification task. However, these are strings and in order to optimise the softmax function in `TensorFlow`, we need numerical IDs instead of strings. We can use the `pandas` map function to do the conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy().drop([\"ocean_proximity\"], axis=1)\n",
    "Y = data.copy()[\"ocean_proximity\"]\n",
    "Y = data.copy()[\"ocean_proximity\"].map({\"<1H OCEAN\":0, \"INLAND\":1, \"ISLAND\": 2, \"NEAR BAY\": 3, \"NEAR OCEAN\": 4}).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split off some data for development and testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, train_size=0.8, random_state=42)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.2, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's preprocess the input features before giving them to the network. We need to fill in missing values with the imputer, and standardise the values to a similar range using the scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn import preprocessing\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(X_train)\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_dev = imputer.transform(X_dev)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_dev = scaler.transform(X_dev)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset that we can work with.\n",
    "\n",
    "Input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(13209, 9)\n(3303, 9)\n(4128, 9)\n[[-0.69155432  1.10281811 -0.12449485 -0.44361185 -0.60289408 -0.48710064\n  -0.64120663  0.44340968 -0.25873131]\n [ 0.8544348  -0.72493883 -1.07770852  1.75575918  1.99734983  1.69902706\n   2.04218568  0.00321001 -0.28999612]\n [ 0.86440892 -0.88428174 -0.20392932 -0.15088981 -0.02963101 -0.13535041\n  -0.16516379 -0.52181236 -0.01729749]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the correstponding gold-standard labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(13209,)\n(3303,)\n(4128,)\n[1 0 0 4 1 1 3 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_dev.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the code examples above, construct a `TensorFlow` model, then train, tune and test it on this dataset. Experiment with different model settings and hyperparameters. Calculate and evaluate classification accuracy - the percentage of datapoints where the predicted class matches the gold-standard class.\n",
    "\n",
    "During the practical session, give examples of what you tried and what your findings were.\n",
    "\n",
    "Some suggestions and tips:\n",
    "\n",
    "- The XOR classification code can be a good place to start.\n",
    "- The output layer needs to have size 5, because the dataset has 5 possible classes.\n",
    "- Try testing on the development set as you are training, to make sure you don't overfit.\n",
    "- Evaluate on the dev set as much as you want, but evaluate on the test set only after you have chosen a good set of hyperparameters.\n",
    "- You could try different learning rates, hidden layer sizes, learning strategies, etc.\n",
    "- Adaptive learning rates can (and sometimes should) be used together with a regular hand-picked learning rate, and different adaptive learning rates can prefer very different regular learning rates.\n",
    "\n",
    "There are a number of additional (optional) steps that you can try: you can visualise your network architecture, changes in loss and metrics, print out and visualise confusion matrices, implement \"traditional\" machine learning algorithms (e.g., from Practicals 2 and 3) and compare the results, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command needed \n",
    "Remove-Item -Recurse -Force -Path ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 694us/step - loss: 0.8447\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 675us/step - loss: 0.5711\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 617us/step - loss: 0.4677\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 622us/step - loss: 0.3832\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 635us/step - loss: 0.3355\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 636us/step - loss: 0.3072\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 605us/step - loss: 0.2846\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 747us/step - loss: 0.2719\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 636us/step - loss: 0.2605\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 646us/step - loss: 0.2499\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 650us/step - loss: 0.2428\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 641us/step - loss: 0.2335\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 655us/step - loss: 0.2282\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 631us/step - loss: 0.2224\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 650us/step - loss: 0.2152\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 607us/step - loss: 0.2115\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 607us/step - loss: 0.2062\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 655us/step - loss: 0.2041\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 578us/step - loss: 0.1983\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 612us/step - loss: 0.1950\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 0s 631us/step - loss: 0.1891\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - 0s 599us/step - loss: 0.1899\n",
      "Epoch 23/100\n",
      "207/207 [==============================] - 0s 633us/step - loss: 0.1865\n",
      "Epoch 24/100\n",
      "207/207 [==============================] - 0s 635us/step - loss: 0.1828\n",
      "Epoch 25/100\n",
      "207/207 [==============================] - 0s 656us/step - loss: 0.1800\n",
      "Epoch 26/100\n",
      "207/207 [==============================] - 0s 597us/step - loss: 0.1786\n",
      "Epoch 27/100\n",
      "207/207 [==============================] - 0s 614us/step - loss: 0.1769\n",
      "Epoch 28/100\n",
      "207/207 [==============================] - 0s 643us/step - loss: 0.1754\n",
      "Epoch 29/100\n",
      "207/207 [==============================] - 0s 684us/step - loss: 0.1741\n",
      "Epoch 30/100\n",
      "207/207 [==============================] - 0s 684us/step - loss: 0.1708\n",
      "Epoch 31/100\n",
      "207/207 [==============================] - 0s 701us/step - loss: 0.1699\n",
      "Epoch 32/100\n",
      "207/207 [==============================] - 0s 659us/step - loss: 0.1701\n",
      "Epoch 33/100\n",
      "207/207 [==============================] - 0s 644us/step - loss: 0.1672\n",
      "Epoch 34/100\n",
      "207/207 [==============================] - 0s 655us/step - loss: 0.1652\n",
      "Epoch 35/100\n",
      "207/207 [==============================] - 0s 664us/step - loss: 0.1647\n",
      "Epoch 36/100\n",
      "207/207 [==============================] - 0s 660us/step - loss: 0.1639\n",
      "Epoch 37/100\n",
      "207/207 [==============================] - 0s 650us/step - loss: 0.1626\n",
      "Epoch 38/100\n",
      "207/207 [==============================] - 0s 689us/step - loss: 0.1612\n",
      "Epoch 39/100\n",
      "207/207 [==============================] - 0s 665us/step - loss: 0.1607\n",
      "Epoch 40/100\n",
      "207/207 [==============================] - 0s 640us/step - loss: 0.1625\n",
      "Epoch 41/100\n",
      "207/207 [==============================] - 0s 668us/step - loss: 0.1588\n",
      "Epoch 42/100\n",
      "207/207 [==============================] - 0s 635us/step - loss: 0.1584\n",
      "Epoch 43/100\n",
      "207/207 [==============================] - 0s 650us/step - loss: 0.1561\n",
      "Epoch 44/100\n",
      "207/207 [==============================] - 0s 626us/step - loss: 0.1559\n",
      "Epoch 45/100\n",
      "207/207 [==============================] - 0s 660us/step - loss: 0.1548\n",
      "Epoch 46/100\n",
      "207/207 [==============================] - 0s 657us/step - loss: 0.1546\n",
      "Epoch 47/100\n",
      "207/207 [==============================] - 0s 607us/step - loss: 0.1529\n",
      "Epoch 48/100\n",
      "207/207 [==============================] - 0s 650us/step - loss: 0.1514\n",
      "Epoch 49/100\n",
      "207/207 [==============================] - 0s 667us/step - loss: 0.1532\n",
      "Epoch 50/100\n",
      "207/207 [==============================] - 0s 646us/step - loss: 0.1500\n",
      "Epoch 51/100\n",
      "207/207 [==============================] - 0s 631us/step - loss: 0.1513\n",
      "Epoch 52/100\n",
      "207/207 [==============================] - 0s 580us/step - loss: 0.1501\n",
      "Epoch 53/100\n",
      "207/207 [==============================] - 0s 694us/step - loss: 0.1518\n",
      "Epoch 54/100\n",
      "207/207 [==============================] - 0s 620us/step - loss: 0.1490\n",
      "Epoch 55/100\n",
      "207/207 [==============================] - 0s 618us/step - loss: 0.1474\n",
      "Epoch 56/100\n",
      "207/207 [==============================] - 0s 674us/step - loss: 0.1482\n",
      "Epoch 57/100\n",
      "207/207 [==============================] - 0s 646us/step - loss: 0.1487\n",
      "Epoch 58/100\n",
      "207/207 [==============================] - 0s 643us/step - loss: 0.1457\n",
      "Epoch 59/100\n",
      "207/207 [==============================] - 0s 677us/step - loss: 0.1452\n",
      "Epoch 60/100\n",
      "207/207 [==============================] - 0s 660us/step - loss: 0.1465\n",
      "Epoch 61/100\n",
      "207/207 [==============================] - 0s 631us/step - loss: 0.1465\n",
      "Epoch 62/100\n",
      "207/207 [==============================] - 0s 666us/step - loss: 0.1442\n",
      "Epoch 63/100\n",
      "207/207 [==============================] - 0s 858us/step - loss: 0.1442\n",
      "Epoch 64/100\n",
      "207/207 [==============================] - 0s 602us/step - loss: 0.1435\n",
      "Epoch 65/100\n",
      "207/207 [==============================] - 0s 585us/step - loss: 0.1426\n",
      "Epoch 66/100\n",
      "207/207 [==============================] - 0s 617us/step - loss: 0.1442\n",
      "Epoch 67/100\n",
      "207/207 [==============================] - 0s 650us/step - loss: 0.1427\n",
      "Epoch 68/100\n",
      "207/207 [==============================] - 0s 668us/step - loss: 0.1405\n",
      "Epoch 69/100\n",
      "207/207 [==============================] - 0s 608us/step - loss: 0.1435\n",
      "Epoch 70/100\n",
      "207/207 [==============================] - 0s 602us/step - loss: 0.1384\n",
      "Epoch 71/100\n",
      "207/207 [==============================] - 0s 679us/step - loss: 0.1398\n",
      "Epoch 72/100\n",
      "207/207 [==============================] - 0s 628us/step - loss: 0.1397\n",
      "Epoch 73/100\n",
      "207/207 [==============================] - 0s 581us/step - loss: 0.1412\n",
      "Epoch 74/100\n",
      "207/207 [==============================] - 0s 607us/step - loss: 0.1398\n",
      "Epoch 75/100\n",
      "207/207 [==============================] - 0s 615us/step - loss: 0.1386\n",
      "Epoch 76/100\n",
      "207/207 [==============================] - 0s 647us/step - loss: 0.1380\n",
      "Epoch 77/100\n",
      "207/207 [==============================] - 0s 653us/step - loss: 0.1361\n",
      "Epoch 78/100\n",
      "207/207 [==============================] - 0s 681us/step - loss: 0.1363\n",
      "Epoch 79/100\n",
      "207/207 [==============================] - 0s 665us/step - loss: 0.1349\n",
      "Epoch 80/100\n",
      "207/207 [==============================] - 0s 660us/step - loss: 0.1365\n",
      "Epoch 81/100\n",
      "207/207 [==============================] - 0s 655us/step - loss: 0.1351\n",
      "Epoch 82/100\n",
      "207/207 [==============================] - 0s 689us/step - loss: 0.1374\n",
      "Epoch 83/100\n",
      "207/207 [==============================] - 0s 674us/step - loss: 0.1346\n",
      "Epoch 84/100\n",
      "207/207 [==============================] - 0s 651us/step - loss: 0.1336\n",
      "Epoch 85/100\n",
      "207/207 [==============================] - 0s 657us/step - loss: 0.1359\n",
      "Epoch 86/100\n",
      "207/207 [==============================] - 0s 663us/step - loss: 0.1356\n",
      "Epoch 87/100\n",
      "207/207 [==============================] - 0s 665us/step - loss: 0.1339\n",
      "Epoch 88/100\n",
      "207/207 [==============================] - 0s 665us/step - loss: 0.1344\n",
      "Epoch 89/100\n",
      "207/207 [==============================] - 0s 694us/step - loss: 0.1340\n",
      "Epoch 90/100\n",
      "207/207 [==============================] - 0s 636us/step - loss: 0.1322\n",
      "Epoch 91/100\n",
      "207/207 [==============================] - 0s 631us/step - loss: 0.1355\n",
      "Epoch 92/100\n",
      "207/207 [==============================] - 0s 685us/step - loss: 0.1333\n",
      "Epoch 93/100\n",
      "207/207 [==============================] - 0s 680us/step - loss: 0.1321\n",
      "Epoch 94/100\n",
      "207/207 [==============================] - 0s 675us/step - loss: 0.1311\n",
      "Epoch 95/100\n",
      "207/207 [==============================] - 0s 669us/step - loss: 0.1337\n",
      "Epoch 96/100\n",
      "207/207 [==============================] - 0s 679us/step - loss: 0.1322\n",
      "Epoch 97/100\n",
      "207/207 [==============================] - 0s 838us/step - loss: 0.1296\n",
      "Epoch 98/100\n",
      "207/207 [==============================] - 0s 708us/step - loss: 0.1316\n",
      "Epoch 99/100\n",
      "207/207 [==============================] - 0s 647us/step - loss: 0.1313\n",
      "Epoch 100/100\n",
      "207/207 [==============================] - 0s 675us/step - loss: 0.1324\n",
      "  1/413 [..............................] - ETA: 0s - loss: 0.1691WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "413/413 [==============================] - 0s 462us/step - loss: 0.2065\n",
      "final loss: 0.20647907257080078\n",
      "WARNING:tensorflow:5 out of the last 54 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000179072DBDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "final predictions:\n",
      "[[5.8212545e-06 9.9999273e-01 1.3836267e-06 2.6248335e-08 8.7169507e-09]\n",
      " [4.5395842e-01 5.4603219e-01 6.9329421e-06 1.2246733e-06 1.2036679e-06]\n",
      " [9.9823749e-01 1.7231053e-03 4.0195296e-06 1.1955137e-07 3.5209723e-05]\n",
      " ...\n",
      " [6.7555279e-01 2.2788960e-03 1.3469299e-04 8.5805915e-08 3.2203349e-01]\n",
      " [9.8907286e-01 1.0913862e-02 4.1470903e-06 1.9260332e-07 8.8712977e-06]\n",
      " [9.9738389e-01 1.4735429e-04 3.2038506e-06 5.3848680e-08 2.4655925e-03]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    #tf.keras.layers.Dense(1, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(64, input_shape=(9,), activation='tanh'),\n",
    "    tf.keras.layers.Dense(32, input_shape=(64,), activation='relu'),\n",
    "    tf.keras.layers.Dense(8, input_shape=(16,), activation='tanh'), # input shape ??\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "nonlinear_model.fit(X_train, y_train, batch_size=64, epochs=100)\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(X_train, y_train))\n",
    "print('final predictions:', nonlinear_model.predict(X_train), sep='\\n')\n",
    "#test_loss, test_acc = nonlinear_model.evaluate(X_train, y_train, verbose=2)\n",
    "#print('\\nAccuracy:', test_acc)"
   ]
  },
  {
   "source": [
    "final loss: 0.2197697013616562 with batch_size=64, epochs=100), depth 2, Adadelta\n",
    "\n",
    "RMS prop = bad performance\n",
    "\n",
    "Adadelta = good\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "After 10 epochs:\n",
      "104/104 - 0s - loss: 1.4896 - accuracy: 0.6194\n",
      "\n",
      "Accuracy: 0.6194368600845337\n",
      "\n",
      "After 20 epochs:\n",
      "104/104 - 0s - loss: 1.3800 - accuracy: 0.6131\n",
      "\n",
      "Accuracy: 0.6130790114402771\n",
      "\n",
      "After 30 epochs:\n",
      "104/104 - 0s - loss: 1.3228 - accuracy: 0.6318\n",
      "\n",
      "Accuracy: 0.6318498253822327\n",
      "\n",
      "After 40 epochs:\n",
      "104/104 - 0s - loss: 1.2873 - accuracy: 0.6609\n",
      "\n",
      "Accuracy: 0.6609143018722534\n",
      "\n",
      "After 50 epochs:\n",
      "104/104 - 0s - loss: 1.2571 - accuracy: 0.6960\n",
      "\n",
      "Accuracy: 0.6960338950157166\n",
      "\n",
      "After 60 epochs:\n",
      "104/104 - 0s - loss: 1.2282 - accuracy: 0.7269\n",
      "\n",
      "Accuracy: 0.7269149422645569\n",
      "\n",
      "After 70 epochs:\n",
      "104/104 - 0s - loss: 1.2029 - accuracy: 0.7466\n",
      "\n",
      "Accuracy: 0.7465940117835999\n",
      "\n",
      "After 80 epochs:\n",
      "104/104 - 0s - loss: 1.1842 - accuracy: 0.7608\n",
      "\n",
      "Accuracy: 0.7608234882354736\n",
      "\n",
      "After 90 epochs:\n",
      "104/104 - 0s - loss: 1.1711 - accuracy: 0.7672\n",
      "\n",
      "Accuracy: 0.7671813368797302\n",
      "\n",
      "After 100 epochs:\n",
      "104/104 - 0s - loss: 1.1614 - accuracy: 0.7705\n",
      "\n",
      "Accuracy: 0.7705116271972656\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    #tf.keras.layers.Dense(1, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(64, input_shape=(9,), activation='tanh'),\n",
    "    tf.keras.layers.Dense(32, input_shape=(64,), activation='relu'),\n",
    "    tf.keras.layers.Dense(8, input_shape=(16,), activation='tanh'), # input shape ?????\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=1),\n",
    "                        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "for epoch in range(100):\n",
    "    nonlinear_model.train_on_batch(X_train, y_train)\n",
    "    predictions = nonlinear_model.predict(X_train)\n",
    "    result = tf.argmax(predictions, axis=1)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        #print('\\nAfter {} epochs:'.format(epoch+1), \" \".join([str(x) for x in result.numpy()]))\n",
    "        print('\\nAfter {} epochs:'.format(epoch+1))\n",
    "        test_loss, test_acc = nonlinear_model.evaluate(X_dev, y_dev, verbose=2)\n",
    "        print('\\nAccuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[5414  138    0  296    0]\n [ 397 3745    0   75    0]\n [   2    0    0    0    0]\n [ 283   78    0 1130    0]\n [1321   61    0  269    0]]\n"
     ]
    }
   ],
   "source": [
    "conf_mx = tf.math.confusion_matrix(y_train, result.numpy()).numpy()\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "207/207 [==============================] - 0s 588us/step - loss: 0.6535\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 554us/step - loss: 0.4857\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 588us/step - loss: 0.4649\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 583us/step - loss: 0.4161\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 549us/step - loss: 0.4104\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 578us/step - loss: 0.3838\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 573us/step - loss: 0.3747\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 583us/step - loss: 0.3756\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 626us/step - loss: 0.3550\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 597us/step - loss: 0.3594\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 564us/step - loss: 0.3438\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 583us/step - loss: 0.3376\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 602us/step - loss: 0.3332\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 588us/step - loss: 0.3389\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 781us/step - loss: 0.3266\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 525us/step - loss: 0.3374\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 546us/step - loss: 0.3230\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 546us/step - loss: 0.3274\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 530us/step - loss: 0.3292\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 544us/step - loss: 0.3209\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 0s 502us/step - loss: 0.3054\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - 0s 539us/step - loss: 0.3148\n",
      "Epoch 23/100\n",
      "207/207 [==============================] - 0s 519us/step - loss: 0.3101\n",
      "Epoch 24/100\n",
      "207/207 [==============================] - 0s 511us/step - loss: 0.3260\n",
      "Epoch 25/100\n",
      "207/207 [==============================] - 0s 536us/step - loss: 0.3061\n",
      "Epoch 26/100\n",
      "207/207 [==============================] - 0s 533us/step - loss: 0.3070\n",
      "Epoch 27/100\n",
      "207/207 [==============================] - 0s 568us/step - loss: 0.3308\n",
      "Epoch 28/100\n",
      "207/207 [==============================] - 0s 546us/step - loss: 0.3104\n",
      "Epoch 29/100\n",
      "207/207 [==============================] - 0s 543us/step - loss: 0.3186\n",
      "Epoch 30/100\n",
      "207/207 [==============================] - 0s 533us/step - loss: 0.3029\n",
      "Epoch 31/100\n",
      "207/207 [==============================] - 0s 535us/step - loss: 0.3116\n",
      "Epoch 32/100\n",
      "207/207 [==============================] - 0s 559us/step - loss: 0.3046\n",
      "Epoch 33/100\n",
      "207/207 [==============================] - 0s 564us/step - loss: 0.3247\n",
      "Epoch 34/100\n",
      "207/207 [==============================] - 0s 558us/step - loss: 0.2943\n",
      "Epoch 35/100\n",
      "207/207 [==============================] - 0s 542us/step - loss: 0.2908\n",
      "Epoch 36/100\n",
      "207/207 [==============================] - 0s 536us/step - loss: 0.3152\n",
      "Epoch 37/100\n",
      "207/207 [==============================] - 0s 511us/step - loss: 0.3129\n",
      "Epoch 38/100\n",
      "207/207 [==============================] - 0s 535us/step - loss: 0.3029\n",
      "Epoch 39/100\n",
      "207/207 [==============================] - 0s 533us/step - loss: 0.2889\n",
      "Epoch 40/100\n",
      "207/207 [==============================] - 0s 518us/step - loss: 0.3014\n",
      "Epoch 41/100\n",
      "207/207 [==============================] - 0s 535us/step - loss: 0.3238\n",
      "Epoch 42/100\n",
      "207/207 [==============================] - 0s 544us/step - loss: 0.3077\n",
      "Epoch 43/100\n",
      "207/207 [==============================] - 0s 555us/step - loss: 0.2855\n",
      "Epoch 44/100\n",
      "207/207 [==============================] - 0s 530us/step - loss: 0.3131\n",
      "Epoch 45/100\n",
      "207/207 [==============================] - 0s 524us/step - loss: 0.3091\n",
      "Epoch 46/100\n",
      "207/207 [==============================] - 0s 593us/step - loss: 0.2958\n",
      "Epoch 47/100\n",
      "207/207 [==============================] - 0s 548us/step - loss: 0.2924\n",
      "Epoch 48/100\n",
      "207/207 [==============================] - 0s 569us/step - loss: 0.2920\n",
      "Epoch 49/100\n",
      "207/207 [==============================] - 0s 558us/step - loss: 0.2896\n",
      "Epoch 50/100\n",
      "207/207 [==============================] - 0s 549us/step - loss: 0.2987\n",
      "Epoch 51/100\n",
      "207/207 [==============================] - 0s 554us/step - loss: 0.2824\n",
      "Epoch 52/100\n",
      "207/207 [==============================] - 0s 542us/step - loss: 0.2819\n",
      "Epoch 53/100\n",
      "207/207 [==============================] - 0s 593us/step - loss: 0.2880\n",
      "Epoch 54/100\n",
      "207/207 [==============================] - 0s 556us/step - loss: 0.2968\n",
      "Epoch 55/100\n",
      "207/207 [==============================] - 0s 592us/step - loss: 0.3085\n",
      "Epoch 56/100\n",
      "207/207 [==============================] - 0s 588us/step - loss: 0.2910\n",
      "Epoch 57/100\n",
      "207/207 [==============================] - 0s 554us/step - loss: 0.2980\n",
      "Epoch 58/100\n",
      "207/207 [==============================] - 0s 530us/step - loss: 0.3005\n",
      "Epoch 59/100\n",
      "207/207 [==============================] - 0s 508us/step - loss: 0.2831\n",
      "Epoch 60/100\n",
      "207/207 [==============================] - 0s 501us/step - loss: 0.2765\n",
      "Epoch 61/100\n",
      "207/207 [==============================] - 0s 534us/step - loss: 0.2800\n",
      "Epoch 62/100\n",
      "207/207 [==============================] - 0s 520us/step - loss: 0.2956\n",
      "Epoch 63/100\n",
      "207/207 [==============================] - 0s 549us/step - loss: 0.2922\n",
      "Epoch 64/100\n",
      "207/207 [==============================] - 0s 544us/step - loss: 0.2929\n",
      "Epoch 65/100\n",
      "207/207 [==============================] - 0s 514us/step - loss: 0.2878\n",
      "Epoch 66/100\n",
      "207/207 [==============================] - 0s 526us/step - loss: 0.2853\n",
      "Epoch 67/100\n",
      "207/207 [==============================] - 0s 529us/step - loss: 0.2813\n",
      "Epoch 68/100\n",
      "207/207 [==============================] - 0s 535us/step - loss: 0.2889\n",
      "Epoch 69/100\n",
      "207/207 [==============================] - 0s 643us/step - loss: 0.2893\n",
      "Epoch 70/100\n",
      "207/207 [==============================] - 0s 641us/step - loss: 0.3045\n",
      "Epoch 71/100\n",
      "207/207 [==============================] - 0s 546us/step - loss: 0.3018\n",
      "Epoch 72/100\n",
      "207/207 [==============================] - 0s 540us/step - loss: 0.2794\n",
      "Epoch 73/100\n",
      "207/207 [==============================] - 0s 525us/step - loss: 0.2927\n",
      "Epoch 74/100\n",
      "207/207 [==============================] - 0s 543us/step - loss: 0.2883\n",
      "Epoch 75/100\n",
      "207/207 [==============================] - 0s 558us/step - loss: 0.3119\n",
      "Epoch 76/100\n",
      "207/207 [==============================] - 0s 576us/step - loss: 0.3140\n",
      "Epoch 77/100\n",
      "207/207 [==============================] - 0s 571us/step - loss: 0.2752\n",
      "Epoch 78/100\n",
      "207/207 [==============================] - 0s 535us/step - loss: 0.2724\n",
      "Epoch 79/100\n",
      "207/207 [==============================] - 0s 571us/step - loss: 0.3012\n",
      "Epoch 80/100\n",
      "207/207 [==============================] - 0s 578us/step - loss: 0.2919\n",
      "Epoch 81/100\n",
      "207/207 [==============================] - 0s 569us/step - loss: 0.2971\n",
      "Epoch 82/100\n",
      "207/207 [==============================] - 0s 549us/step - loss: 0.2938\n",
      "Epoch 83/100\n",
      "207/207 [==============================] - 0s 540us/step - loss: 0.2793\n",
      "Epoch 84/100\n",
      "207/207 [==============================] - 0s 564us/step - loss: 0.2991\n",
      "Epoch 85/100\n",
      "207/207 [==============================] - 0s 569us/step - loss: 0.3038\n",
      "Epoch 86/100\n",
      "207/207 [==============================] - 0s 569us/step - loss: 0.3292\n",
      "Epoch 87/100\n",
      "207/207 [==============================] - 0s 585us/step - loss: 0.2873\n",
      "Epoch 88/100\n",
      "207/207 [==============================] - 0s 573us/step - loss: 0.2690\n",
      "Epoch 89/100\n",
      "207/207 [==============================] - 0s 545us/step - loss: 0.2931\n",
      "Epoch 90/100\n",
      "207/207 [==============================] - 0s 578us/step - loss: 0.2664\n",
      "Epoch 91/100\n",
      "207/207 [==============================] - 0s 522us/step - loss: 0.2916\n",
      "Epoch 92/100\n",
      "207/207 [==============================] - 0s 548us/step - loss: 0.2991\n",
      "Epoch 93/100\n",
      "207/207 [==============================] - 0s 540us/step - loss: 0.3112\n",
      "Epoch 94/100\n",
      "207/207 [==============================] - 0s 536us/step - loss: 0.2979\n",
      "Epoch 95/100\n",
      "207/207 [==============================] - 0s 552us/step - loss: 0.2810\n",
      "Epoch 96/100\n",
      "207/207 [==============================] - 0s 612us/step - loss: 0.3152\n",
      "Epoch 97/100\n",
      "207/207 [==============================] - 0s 572us/step - loss: 0.2682\n",
      "Epoch 98/100\n",
      "207/207 [==============================] - 0s 546us/step - loss: 0.2772\n",
      "Epoch 99/100\n",
      "207/207 [==============================] - 0s 547us/step - loss: 0.2987\n",
      "Epoch 100/100\n",
      "207/207 [==============================] - 0s 583us/step - loss: 0.2767\n",
      "413/413 [==============================] - 0s 468us/step - loss: 0.2719\n",
      "final loss: 0.2719167172908783\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "nonlinear_model.fit(X_train, y_train, batch_size=64, epochs=100)\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(X_train, y_train))\n",
    "#print('final predictions:', nonlinear_model.predict(xor_input), sep='\\n')"
   ]
  },
  {
   "source": [
    "## Tensorboard"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "  2/207 [..............................] - ETA: 3:38 - loss: 1.5968WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 2.1341s). Check your callbacks.\n",
      "207/207 [==============================] - 2s 12ms/step - loss: 0.8502 - val_loss: 0.6224\n",
      "Epoch 2/100\n",
      "207/207 [==============================] - 0s 824us/step - loss: 0.5086 - val_loss: 0.4446\n",
      "Epoch 3/100\n",
      "207/207 [==============================] - 0s 834us/step - loss: 0.4018 - val_loss: 0.3779\n",
      "Epoch 4/100\n",
      "207/207 [==============================] - 0s 930us/step - loss: 0.3527 - val_loss: 0.3418\n",
      "Epoch 5/100\n",
      "207/207 [==============================] - 0s 848us/step - loss: 0.3279 - val_loss: 0.3625\n",
      "Epoch 6/100\n",
      "207/207 [==============================] - 0s 867us/step - loss: 0.3110 - val_loss: 0.3274\n",
      "Epoch 7/100\n",
      "207/207 [==============================] - 0s 790us/step - loss: 0.2931 - val_loss: 0.3340\n",
      "Epoch 8/100\n",
      "207/207 [==============================] - 0s 838us/step - loss: 0.2826 - val_loss: 0.2971\n",
      "Epoch 9/100\n",
      "207/207 [==============================] - 0s 867us/step - loss: 0.2722 - val_loss: 0.2788\n",
      "Epoch 10/100\n",
      "207/207 [==============================] - 0s 882us/step - loss: 0.2597 - val_loss: 0.2675\n",
      "Epoch 11/100\n",
      "207/207 [==============================] - 0s 882us/step - loss: 0.2528 - val_loss: 0.2645\n",
      "Epoch 12/100\n",
      "207/207 [==============================] - 0s 882us/step - loss: 0.2437 - val_loss: 0.2517\n",
      "Epoch 13/100\n",
      "207/207 [==============================] - 0s 848us/step - loss: 0.2401 - val_loss: 0.2605\n",
      "Epoch 14/100\n",
      "207/207 [==============================] - 0s 809us/step - loss: 0.2332 - val_loss: 0.2449\n",
      "Epoch 15/100\n",
      "207/207 [==============================] - 0s 795us/step - loss: 0.2277 - val_loss: 0.2470\n",
      "Epoch 16/100\n",
      "207/207 [==============================] - 0s 752us/step - loss: 0.2225 - val_loss: 0.2187\n",
      "Epoch 17/100\n",
      "207/207 [==============================] - 0s 776us/step - loss: 0.2180 - val_loss: 0.2356\n",
      "Epoch 18/100\n",
      "207/207 [==============================] - 0s 781us/step - loss: 0.2146 - val_loss: 0.2224\n",
      "Epoch 19/100\n",
      "207/207 [==============================] - 0s 824us/step - loss: 0.2099 - val_loss: 0.2178\n",
      "Epoch 20/100\n",
      "207/207 [==============================] - 0s 829us/step - loss: 0.2049 - val_loss: 0.2127\n",
      "Epoch 21/100\n",
      "207/207 [==============================] - 0s 853us/step - loss: 0.1995 - val_loss: 0.1960\n",
      "Epoch 22/100\n",
      "207/207 [==============================] - 0s 814us/step - loss: 0.1992 - val_loss: 0.2045\n",
      "Epoch 23/100\n",
      "207/207 [==============================] - 0s 785us/step - loss: 0.1958 - val_loss: 0.2102\n",
      "Epoch 24/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1920 - val_loss: 0.2746\n",
      "Epoch 25/100\n",
      "207/207 [==============================] - 0s 858us/step - loss: 0.1897 - val_loss: 0.2095\n",
      "Epoch 26/100\n",
      "207/207 [==============================] - 0s 838us/step - loss: 0.1881 - val_loss: 0.2143\n",
      "Epoch 27/100\n",
      "207/207 [==============================] - 0s 824us/step - loss: 0.1848 - val_loss: 0.2348\n",
      "Epoch 28/100\n",
      "207/207 [==============================] - 0s 824us/step - loss: 0.1825 - val_loss: 0.2028\n",
      "Epoch 29/100\n",
      "207/207 [==============================] - 0s 814us/step - loss: 0.1822 - val_loss: 0.2041\n",
      "Epoch 30/100\n",
      "207/207 [==============================] - 0s 805us/step - loss: 0.1775 - val_loss: 0.2305\n",
      "Epoch 31/100\n",
      "207/207 [==============================] - 0s 824us/step - loss: 0.1767 - val_loss: 0.2082\n",
      "Epoch 32/100\n",
      "207/207 [==============================] - 0s 957us/step - loss: 0.1773 - val_loss: 0.2367\n",
      "Epoch 33/100\n",
      "207/207 [==============================] - 0s 870us/step - loss: 0.1745 - val_loss: 0.2048\n",
      "Epoch 34/100\n",
      "207/207 [==============================] - 0s 902us/step - loss: 0.1728 - val_loss: 0.2183\n",
      "Epoch 35/100\n",
      "207/207 [==============================] - 0s 874us/step - loss: 0.1723 - val_loss: 0.2279\n",
      "Epoch 36/100\n",
      "207/207 [==============================] - 0s 865us/step - loss: 0.1709 - val_loss: 0.1771\n",
      "Epoch 37/100\n",
      "207/207 [==============================] - 0s 908us/step - loss: 0.1692 - val_loss: 0.1900\n",
      "Epoch 38/100\n",
      "207/207 [==============================] - 0s 955us/step - loss: 0.1675 - val_loss: 0.2068\n",
      "Epoch 39/100\n",
      "207/207 [==============================] - 0s 957us/step - loss: 0.1674 - val_loss: 0.1860\n",
      "Epoch 40/100\n",
      "207/207 [==============================] - 0s 925us/step - loss: 0.1676 - val_loss: 0.1798\n",
      "Epoch 41/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1645 - val_loss: 0.2370\n",
      "Epoch 42/100\n",
      "207/207 [==============================] - 0s 896us/step - loss: 0.1639 - val_loss: 0.2220\n",
      "Epoch 43/100\n",
      "207/207 [==============================] - 0s 882us/step - loss: 0.1627 - val_loss: 0.1660\n",
      "Epoch 44/100\n",
      "207/207 [==============================] - 0s 849us/step - loss: 0.1614 - val_loss: 0.2342\n",
      "Epoch 45/100\n",
      "207/207 [==============================] - 0s 865us/step - loss: 0.1620 - val_loss: 0.1889\n",
      "Epoch 46/100\n",
      "207/207 [==============================] - 0s 836us/step - loss: 0.1611 - val_loss: 0.1837\n",
      "Epoch 47/100\n",
      "207/207 [==============================] - 0s 958us/step - loss: 0.1588 - val_loss: 0.2355\n",
      "Epoch 48/100\n",
      "207/207 [==============================] - 0s 875us/step - loss: 0.1583 - val_loss: 0.2054\n",
      "Epoch 49/100\n",
      "207/207 [==============================] - 0s 886us/step - loss: 0.1591 - val_loss: 0.1709\n",
      "Epoch 50/100\n",
      "207/207 [==============================] - 0s 891us/step - loss: 0.1552 - val_loss: 0.2169\n",
      "Epoch 51/100\n",
      "207/207 [==============================] - 0s 831us/step - loss: 0.1579 - val_loss: 0.1879\n",
      "Epoch 52/100\n",
      "207/207 [==============================] - 0s 878us/step - loss: 0.1571 - val_loss: 0.2530\n",
      "Epoch 53/100\n",
      "207/207 [==============================] - 0s 877us/step - loss: 0.1562 - val_loss: 0.1771\n",
      "Epoch 54/100\n",
      "207/207 [==============================] - 0s 866us/step - loss: 0.1542 - val_loss: 0.1728\n",
      "Epoch 55/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1521 - val_loss: 0.1797\n",
      "Epoch 56/100\n",
      "207/207 [==============================] - 0s 905us/step - loss: 0.1556 - val_loss: 0.1589\n",
      "Epoch 57/100\n",
      "207/207 [==============================] - 0s 841us/step - loss: 0.1553 - val_loss: 0.1887\n",
      "Epoch 58/100\n",
      "207/207 [==============================] - 0s 844us/step - loss: 0.1531 - val_loss: 0.1832\n",
      "Epoch 59/100\n",
      "207/207 [==============================] - 0s 935us/step - loss: 0.1506 - val_loss: 0.1615\n",
      "Epoch 60/100\n",
      "207/207 [==============================] - 0s 878us/step - loss: 0.1530 - val_loss: 0.1982\n",
      "Epoch 61/100\n",
      "207/207 [==============================] - 0s 822us/step - loss: 0.1520 - val_loss: 0.1892\n",
      "Epoch 62/100\n",
      "207/207 [==============================] - 0s 841us/step - loss: 0.1513 - val_loss: 0.1750\n",
      "Epoch 63/100\n",
      "207/207 [==============================] - 0s 932us/step - loss: 0.1511 - val_loss: 0.1899\n",
      "Epoch 64/100\n",
      "207/207 [==============================] - 0s 869us/step - loss: 0.1507 - val_loss: 0.1814\n",
      "Epoch 65/100\n",
      "207/207 [==============================] - 0s 890us/step - loss: 0.1491 - val_loss: 0.1956\n",
      "Epoch 66/100\n",
      "207/207 [==============================] - 0s 901us/step - loss: 0.1515 - val_loss: 0.1646\n",
      "Epoch 67/100\n",
      "207/207 [==============================] - 0s 959us/step - loss: 0.1498 - val_loss: 0.2059\n",
      "Epoch 68/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1482 - val_loss: 0.1778\n",
      "Epoch 69/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1492 - val_loss: 0.2318\n",
      "Epoch 70/100\n",
      "207/207 [==============================] - 0s 925us/step - loss: 0.1442 - val_loss: 0.2441\n",
      "Epoch 71/100\n",
      "207/207 [==============================] - 0s 888us/step - loss: 0.1479 - val_loss: 0.1608\n",
      "Epoch 72/100\n",
      "207/207 [==============================] - 0s 849us/step - loss: 0.1460 - val_loss: 0.1551\n",
      "Epoch 73/100\n",
      "207/207 [==============================] - 0s 879us/step - loss: 0.1493 - val_loss: 0.2077\n",
      "Epoch 74/100\n",
      "207/207 [==============================] - 0s 867us/step - loss: 0.1455 - val_loss: 0.1739\n",
      "Epoch 75/100\n",
      "207/207 [==============================] - 0s 890us/step - loss: 0.1474 - val_loss: 0.1779\n",
      "Epoch 76/100\n",
      "207/207 [==============================] - 0s 847us/step - loss: 0.1429 - val_loss: 0.2237\n",
      "Epoch 77/100\n",
      "207/207 [==============================] - 0s 865us/step - loss: 0.1433 - val_loss: 0.2312\n",
      "Epoch 78/100\n",
      "207/207 [==============================] - 0s 803us/step - loss: 0.1429 - val_loss: 0.2095\n",
      "Epoch 79/100\n",
      "207/207 [==============================] - 0s 912us/step - loss: 0.1436 - val_loss: 0.1643\n",
      "Epoch 80/100\n",
      "207/207 [==============================] - 0s 919us/step - loss: 0.1416 - val_loss: 0.1857\n",
      "Epoch 81/100\n",
      "207/207 [==============================] - 0s 871us/step - loss: 0.1398 - val_loss: 0.1998\n",
      "Epoch 82/100\n",
      "207/207 [==============================] - 0s 830us/step - loss: 0.1428 - val_loss: 0.1607\n",
      "Epoch 83/100\n",
      "207/207 [==============================] - 0s 863us/step - loss: 0.1407 - val_loss: 0.1815\n",
      "Epoch 84/100\n",
      "207/207 [==============================] - 0s 911us/step - loss: 0.1416 - val_loss: 0.1636\n",
      "Epoch 85/100\n",
      "207/207 [==============================] - 0s 893us/step - loss: 0.1414 - val_loss: 0.1976\n",
      "Epoch 86/100\n",
      "207/207 [==============================] - 0s 901us/step - loss: 0.1448 - val_loss: 0.1541\n",
      "Epoch 87/100\n",
      "207/207 [==============================] - 0s 857us/step - loss: 0.1408 - val_loss: 0.1541\n",
      "Epoch 88/100\n",
      "207/207 [==============================] - 0s 899us/step - loss: 0.1411 - val_loss: 0.2422\n",
      "Epoch 89/100\n",
      "207/207 [==============================] - 0s 863us/step - loss: 0.1406 - val_loss: 0.1940\n",
      "Epoch 90/100\n",
      "207/207 [==============================] - 0s 878us/step - loss: 0.1407 - val_loss: 0.1710\n",
      "Epoch 91/100\n",
      "207/207 [==============================] - 0s 918us/step - loss: 0.1419 - val_loss: 0.2244\n",
      "Epoch 92/100\n",
      "207/207 [==============================] - 0s 870us/step - loss: 0.1395 - val_loss: 0.1532\n",
      "Epoch 93/100\n",
      "207/207 [==============================] - 0s 882us/step - loss: 0.1390 - val_loss: 0.1990\n",
      "Epoch 94/100\n",
      "207/207 [==============================] - 0s 932us/step - loss: 0.1363 - val_loss: 0.1735\n",
      "Epoch 95/100\n",
      "207/207 [==============================] - 0s 946us/step - loss: 0.1386 - val_loss: 0.1571\n",
      "Epoch 96/100\n",
      "207/207 [==============================] - 0s 954us/step - loss: 0.1372 - val_loss: 0.1760\n",
      "Epoch 97/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1375 - val_loss: 0.1542\n",
      "Epoch 98/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1352 - val_loss: 0.2579\n",
      "Epoch 99/100\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1359 - val_loss: 0.1556\n",
      "Epoch 100/100\n",
      "207/207 [==============================] - 0s 954us/step - loss: 0.1361 - val_loss: 0.1711\n",
      "104/104 [==============================] - 0s 470us/step - loss: 0.1711\n",
      "final loss: 0.17112526297569275\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(9,), activation='tanh'),\n",
    "    tf.keras.layers.Dense(32, input_shape=(64,), activation='relu'),\n",
    "    tf.keras.layers.Dense(8, input_shape=(16,), activation='tanh'), # input shape ?????\n",
    "    tf.keras.layers.Dense(5, activation='softmax')])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "nonlinear_model.fit(X_train, y_train, \n",
    "                    batch_size=64, epochs=100, \n",
    "                    validation_data=(X_dev, y_dev),\n",
    "                    callbacks=[tensorboard_callback])\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(X_dev, y_dev))\n",
    "#print('final predictions:', nonlinear_model.predict(xor_input), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 3400), started 1:59:34 ago. (Use '!kill 3400' to kill it.)"
     },
     "metadata": {}
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit --host localhost\n",
    "# or go to http://localhost:6006/"
   ]
  },
  {
   "source": [
    "## Keeping track of the history"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, input_shape=(9,), activation='tanh'),\n",
    "    tf.keras.layers.Dense(32, input_shape=(64,), activation='relu'),\n",
    "    tf.keras.layers.Dense(8, input_shape=(16,), activation='tanh'), # input shape ?????\n",
    "    tf.keras.layers.Dense(5, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x179004a29a0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x17900791d00>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x17908b93100>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x179006afc10>]"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "nonlinear_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 64)                640       \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_2 (Dense)              (None, 8)                 264       \n_________________________________________________________________\ndense_3 (Dense)              (None, 5)                 45        \n=================================================================\nTotal params: 3,029\nTrainable params: 3,029\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nonlinear_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(nonlinear_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'dense_1'"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "hidden1 = nonlinear_model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.06223363, -0.22846657, -0.07689464, ..., -0.10932827,\n",
       "         0.02013302,  0.23874688],\n",
       "       [ 0.2138378 , -0.14235729, -0.16573298, ..., -0.16302538,\n",
       "         0.10364157,  0.01436538],\n",
       "       [-0.14882928,  0.22484434,  0.1843    , ...,  0.23599887,\n",
       "        -0.18232685,  0.0294525 ],\n",
       "       ...,\n",
       "       [-0.2431221 , -0.0520643 , -0.10374695, ..., -0.09917325,\n",
       "        -0.07757515, -0.06648576],\n",
       "       [-0.19586313,  0.01084602, -0.03111851, ...,  0.16966844,\n",
       "        -0.14623338, -0.24761206],\n",
       "       [-0.05921841, -0.22297907,  0.21548402, ..., -0.01424277,\n",
       "         0.1579057 , -0.1023556 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(64, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "207/207 [==============================] - 0s 2ms/step - loss: 0.8715 - accuracy: 0.6994 - val_loss: 0.6067 - val_accuracy: 0.7735\n",
      "Epoch 2/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.8036 - val_loss: 0.4501 - val_accuracy: 0.8214\n",
      "Epoch 3/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8412 - val_loss: 0.3733 - val_accuracy: 0.8625\n",
      "Epoch 4/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8537 - val_loss: 0.3435 - val_accuracy: 0.8535\n",
      "Epoch 5/50\n",
      "207/207 [==============================] - 0s 990us/step - loss: 0.3309 - accuracy: 0.8643 - val_loss: 0.3383 - val_accuracy: 0.8635\n",
      "Epoch 6/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8738 - val_loss: 0.3282 - val_accuracy: 0.8622\n",
      "Epoch 7/50\n",
      "207/207 [==============================] - 0s 997us/step - loss: 0.2937 - accuracy: 0.8793 - val_loss: 0.3258 - val_accuracy: 0.8686\n",
      "Epoch 8/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2834 - accuracy: 0.8839 - val_loss: 0.2864 - val_accuracy: 0.8856\n",
      "Epoch 9/50\n",
      "207/207 [==============================] - 0s 967us/step - loss: 0.2735 - accuracy: 0.8889 - val_loss: 0.2842 - val_accuracy: 0.8795\n",
      "Epoch 10/50\n",
      "207/207 [==============================] - 0s 934us/step - loss: 0.2626 - accuracy: 0.8941 - val_loss: 0.2703 - val_accuracy: 0.8859\n",
      "Epoch 11/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2563 - accuracy: 0.8942 - val_loss: 0.2620 - val_accuracy: 0.8910\n",
      "Epoch 12/50\n",
      "207/207 [==============================] - 0s 994us/step - loss: 0.2465 - accuracy: 0.8990 - val_loss: 0.2508 - val_accuracy: 0.9074\n",
      "Epoch 13/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.9021 - val_loss: 0.2804 - val_accuracy: 0.8789\n",
      "Epoch 14/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2341 - accuracy: 0.9051 - val_loss: 0.2500 - val_accuracy: 0.8880\n",
      "Epoch 15/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9107 - val_loss: 0.2554 - val_accuracy: 0.9031\n",
      "Epoch 16/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.9104 - val_loss: 0.2197 - val_accuracy: 0.9152\n",
      "Epoch 17/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9120 - val_loss: 0.2244 - val_accuracy: 0.9092\n",
      "Epoch 18/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.9144 - val_loss: 0.2166 - val_accuracy: 0.9131\n",
      "Epoch 19/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.9176 - val_loss: 0.2142 - val_accuracy: 0.9134\n",
      "Epoch 20/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.9156 - val_loss: 0.2106 - val_accuracy: 0.9195\n",
      "Epoch 21/50\n",
      "207/207 [==============================] - 0s 940us/step - loss: 0.2004 - accuracy: 0.9206 - val_loss: 0.1979 - val_accuracy: 0.9228\n",
      "Epoch 22/50\n",
      "207/207 [==============================] - 0s 960us/step - loss: 0.2008 - accuracy: 0.9179 - val_loss: 0.2081 - val_accuracy: 0.9195\n",
      "Epoch 23/50\n",
      "207/207 [==============================] - 0s 987us/step - loss: 0.1971 - accuracy: 0.9195 - val_loss: 0.2268 - val_accuracy: 0.9077\n",
      "Epoch 24/50\n",
      "207/207 [==============================] - 0s 917us/step - loss: 0.1943 - accuracy: 0.9227 - val_loss: 0.2505 - val_accuracy: 0.8989\n",
      "Epoch 25/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9205 - val_loss: 0.2142 - val_accuracy: 0.9228\n",
      "Epoch 26/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.9229 - val_loss: 0.2080 - val_accuracy: 0.9177\n",
      "Epoch 27/50\n",
      "207/207 [==============================] - 0s 949us/step - loss: 0.1890 - accuracy: 0.9254 - val_loss: 0.2406 - val_accuracy: 0.9064\n",
      "Epoch 28/50\n",
      "207/207 [==============================] - 0s 964us/step - loss: 0.1851 - accuracy: 0.9252 - val_loss: 0.1896 - val_accuracy: 0.9246\n",
      "Epoch 29/50\n",
      "207/207 [==============================] - 0s 949us/step - loss: 0.1838 - accuracy: 0.9275 - val_loss: 0.2044 - val_accuracy: 0.9192\n",
      "Epoch 30/50\n",
      "207/207 [==============================] - 0s 941us/step - loss: 0.1810 - accuracy: 0.9267 - val_loss: 0.2186 - val_accuracy: 0.9155\n",
      "Epoch 31/50\n",
      "207/207 [==============================] - 0s 952us/step - loss: 0.1799 - accuracy: 0.9269 - val_loss: 0.1928 - val_accuracy: 0.9207\n",
      "Epoch 32/50\n",
      "207/207 [==============================] - 0s 997us/step - loss: 0.1778 - accuracy: 0.9278 - val_loss: 0.2051 - val_accuracy: 0.9195\n",
      "Epoch 33/50\n",
      "207/207 [==============================] - 0s 943us/step - loss: 0.1769 - accuracy: 0.9268 - val_loss: 0.1898 - val_accuracy: 0.9252\n",
      "Epoch 34/50\n",
      "207/207 [==============================] - 0s 892us/step - loss: 0.1745 - accuracy: 0.9291 - val_loss: 0.2058 - val_accuracy: 0.9164\n",
      "Epoch 35/50\n",
      "207/207 [==============================] - 0s 895us/step - loss: 0.1729 - accuracy: 0.9276 - val_loss: 0.2319 - val_accuracy: 0.9113\n",
      "Epoch 36/50\n",
      "207/207 [==============================] - 0s 941us/step - loss: 0.1739 - accuracy: 0.9285 - val_loss: 0.2089 - val_accuracy: 0.9222\n",
      "Epoch 37/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1703 - accuracy: 0.9301 - val_loss: 0.1922 - val_accuracy: 0.9255\n",
      "Epoch 38/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.9284 - val_loss: 0.1971 - val_accuracy: 0.9140\n",
      "Epoch 39/50\n",
      "207/207 [==============================] - 0s 994us/step - loss: 0.1676 - accuracy: 0.9299 - val_loss: 0.1755 - val_accuracy: 0.9331\n",
      "Epoch 40/50\n",
      "207/207 [==============================] - 0s 917us/step - loss: 0.1684 - accuracy: 0.9315 - val_loss: 0.1866 - val_accuracy: 0.9219\n",
      "Epoch 41/50\n",
      "207/207 [==============================] - 0s 989us/step - loss: 0.1663 - accuracy: 0.9298 - val_loss: 0.2105 - val_accuracy: 0.9167\n",
      "Epoch 42/50\n",
      "207/207 [==============================] - 0s 913us/step - loss: 0.1642 - accuracy: 0.9304 - val_loss: 0.1981 - val_accuracy: 0.9261\n",
      "Epoch 43/50\n",
      "207/207 [==============================] - 0s 920us/step - loss: 0.1631 - accuracy: 0.9316 - val_loss: 0.1726 - val_accuracy: 0.9337\n",
      "Epoch 44/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.9321 - val_loss: 0.2496 - val_accuracy: 0.9046\n",
      "Epoch 45/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.9336 - val_loss: 0.1857 - val_accuracy: 0.9237\n",
      "Epoch 46/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9333 - val_loss: 0.1972 - val_accuracy: 0.9216\n",
      "Epoch 47/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9330 - val_loss: 0.2224 - val_accuracy: 0.9173\n",
      "Epoch 48/50\n",
      "207/207 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9359 - val_loss: 0.1920 - val_accuracy: 0.9234\n",
      "Epoch 49/50\n",
      "207/207 [==============================] - 0s 959us/step - loss: 0.1579 - accuracy: 0.9325 - val_loss: 0.1709 - val_accuracy: 0.9337\n",
      "Epoch 50/50\n",
      "207/207 [==============================] - 0s 991us/step - loss: 0.1555 - accuracy: 0.9349 - val_loss: 0.2178 - val_accuracy: 0.9128\n"
     ]
    }
   ],
   "source": [
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.Adadelta(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                       metrics = ['accuracy'])\n",
    "                       \n",
    "history = nonlinear_model.fit(X_train, y_train, batch_size=64, epochs=50,\n",
    "                    validation_data=(X_dev, y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 50, 'steps': 207}"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"306.677344pt\" version=\"1.1\" viewBox=\"0 0 483.703125 306.677344\" width=\"483.703125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-11-24T12:45:28.281498</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 306.677344 \r\nL 483.703125 306.677344 \r\nL 483.703125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 282.799219 \r\nL 476.503125 282.799219 \r\nL 476.503125 10.999219 \r\nL 30.103125 10.999219 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 50.394034 282.799219 \r\nL 50.394034 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_2\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m76c994d1cb\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.394034\" xlink:href=\"#m76c994d1cb\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(47.212784 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 133.214071 282.799219 \r\nL 133.214071 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"133.214071\" xlink:href=\"#m76c994d1cb\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(126.851571 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 216.034108 282.799219 \r\nL 216.034108 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"216.034108\" xlink:href=\"#m76c994d1cb\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(209.671608 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 298.854145 282.799219 \r\nL 298.854145 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"298.854145\" xlink:href=\"#m76c994d1cb\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 30 -->\r\n      <g transform=\"translate(292.491645 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 381.674183 282.799219 \r\nL 381.674183 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"381.674183\" xlink:href=\"#m76c994d1cb\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(375.311683 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 464.49422 282.799219 \r\nL 464.49422 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"464.49422\" xlink:href=\"#m76c994d1cb\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(458.13172 297.397656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_13\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 30.103125 282.799219 \r\nL 476.503125 282.799219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_14\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m3265443578\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m3265443578\" y=\"282.799219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(7.2 286.598437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_15\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 30.103125 228.439219 \r\nL 476.503125 228.439219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m3265443578\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(7.2 232.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_17\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 30.103125 174.079219 \r\nL 476.503125 174.079219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m3265443578\" y=\"174.079219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.4 -->\r\n      <g transform=\"translate(7.2 177.878437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_19\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 30.103125 119.719219 \r\nL 476.503125 119.719219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m3265443578\" y=\"119.719219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.6 -->\r\n      <g transform=\"translate(7.2 123.518437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_21\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 30.103125 65.359219 \r\nL 476.503125 65.359219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m3265443578\" y=\"65.359219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.8 -->\r\n      <g transform=\"translate(7.2 69.158437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_23\">\r\n      <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 30.103125 10.999219 \r\nL 476.503125 10.999219 \r\n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\r\n     </g>\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m3265443578\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_25\">\r\n    <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 50.394034 45.920071 \r\nL 58.676038 143.242643 \r\nL 66.958042 171.851035 \r\nL 75.240045 185.06798 \r\nL 83.522049 192.849457 \r\nL 91.804053 197.934078 \r\nL 100.086056 202.960167 \r\nL 108.36806 205.767332 \r\nL 116.650064 208.469907 \r\nL 124.932067 211.436826 \r\nL 133.214071 213.140442 \r\nL 141.496075 215.803046 \r\nL 149.778079 217.231237 \r\nL 158.060082 219.173297 \r\nL 166.342086 220.577524 \r\nL 174.62409 222.33551 \r\nL 182.906093 223.374511 \r\nL 191.188097 224.282949 \r\nL 199.470101 225.695761 \r\nL 207.752105 226.52284 \r\nL 216.034108 228.340856 \r\nL 224.316112 228.230697 \r\nL 232.598116 229.236629 \r\nL 240.880119 229.993737 \r\nL 249.162123 230.60163 \r\nL 257.444127 231.467512 \r\nL 265.726131 231.432017 \r\nL 274.008134 232.500034 \r\nL 282.290138 232.839796 \r\nL 290.572142 233.610812 \r\nL 298.854145 233.905018 \r\nL 307.136149 234.467496 \r\nL 315.418153 234.707714 \r\nL 323.700157 235.373832 \r\nL 331.98216 235.816228 \r\nL 340.264164 235.535562 \r\nL 348.546168 236.503196 \r\nL 356.828171 236.612343 \r\nL 365.110175 237.232569 \r\nL 373.392179 237.034104 \r\nL 381.674183 237.594311 \r\nL 389.956186 238.160621 \r\nL 398.23819 238.475316 \r\nL 406.520194 238.65575 \r\nL 414.802197 239.07892 \r\nL 423.084201 239.436041 \r\nL 431.366205 239.428512 \r\nL 439.648208 240.282402 \r\nL 447.930212 239.888923 \r\nL 456.212216 240.539298 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_26\">\r\n    <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 50.394034 92.710008 \r\nL 58.676038 64.375648 \r\nL 66.958042 54.148942 \r\nL 75.240045 50.753746 \r\nL 83.522049 47.893556 \r\nL 91.804053 45.30087 \r\nL 100.086056 43.798772 \r\nL 108.36806 42.54357 \r\nL 116.650064 41.20607 \r\nL 124.932067 39.78627 \r\nL 133.214071 39.745121 \r\nL 141.496075 38.44877 \r\nL 149.778079 37.605127 \r\nL 158.060082 36.802633 \r\nL 166.342086 35.279944 \r\nL 174.62409 35.362243 \r\nL 182.906093 34.930125 \r\nL 191.188097 34.271671 \r\nL 199.470101 33.407436 \r\nL 207.752105 33.942443 \r\nL 216.034108 32.584368 \r\nL 224.316112 33.325138 \r\nL 232.598116 32.872446 \r\nL 240.880119 32.008212 \r\nL 249.162123 32.604943 \r\nL 257.444127 31.946488 \r\nL 265.726131 31.288017 \r\nL 274.008134 31.329182 \r\nL 282.290138 30.711877 \r\nL 290.572142 30.91764 \r\nL 298.854145 30.8559 \r\nL 307.136149 30.629562 \r\nL 315.418153 30.897065 \r\nL 323.700157 30.259185 \r\nL 331.98216 30.670711 \r\nL 340.264164 30.444373 \r\nL 348.546168 29.991682 \r\nL 356.828171 30.464948 \r\nL 365.110175 30.053406 \r\nL 373.392179 29.621289 \r\nL 381.674183 30.07398 \r\nL 389.956186 29.929941 \r\nL 398.23819 29.600714 \r\nL 406.520194 29.456675 \r\nL 414.802197 29.045149 \r\nL 423.084201 29.127448 \r\nL 431.366205 29.209763 \r\nL 439.648208 28.427843 \r\nL 447.930212 29.333211 \r\nL 456.212216 28.69533 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_27\">\r\n    <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 50.394034 117.90514 \r\nL 58.676038 160.45286 \r\nL 66.958042 181.33804 \r\nL 75.240045 189.443083 \r\nL 83.522049 190.848593 \r\nL 91.804053 193.603754 \r\nL 100.086056 194.254806 \r\nL 108.36806 204.954316 \r\nL 116.650064 205.545199 \r\nL 124.932067 209.329419 \r\nL 133.214071 211.586535 \r\nL 141.496075 214.622152 \r\nL 149.778079 206.597626 \r\nL 158.060082 214.860879 \r\nL 166.342086 213.382057 \r\nL 174.62409 223.097283 \r\nL 182.906093 221.793849 \r\nL 191.188097 223.934106 \r\nL 199.470101 224.580127 \r\nL 207.752105 225.564517 \r\nL 216.034108 229.018809 \r\nL 224.316112 226.240978 \r\nL 232.598116 221.152015 \r\nL 240.880119 214.721704 \r\nL 249.162123 224.590504 \r\nL 257.444127 226.257074 \r\nL 265.726131 217.417219 \r\nL 274.008134 231.262013 \r\nL 282.290138 227.239766 \r\nL 290.572142 223.379598 \r\nL 298.854145 230.407803 \r\nL 307.136149 227.048632 \r\nL 315.418153 231.217886 \r\nL 323.700157 226.870139 \r\nL 331.98216 219.773495 \r\nL 340.264164 226.01025 \r\nL 348.546168 230.56338 \r\nL 356.828171 229.240845 \r\nL 365.110175 235.090302 \r\nL 373.392179 232.067771 \r\nL 381.674183 225.585671 \r\nL 389.956186 228.968514 \r\nL 398.23819 235.890904 \r\nL 406.520194 214.950237 \r\nL 414.802197 232.316542 \r\nL 423.084201 229.193572 \r\nL 431.366205 222.345246 \r\nL 439.648208 230.609248 \r\nL 447.930212 236.350328 \r\nL 456.212216 223.587779 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_28\">\r\n    <path clip-path=\"url(#p8ae2ea1b2d)\" d=\"M 50.394034 72.551268 \r\nL 58.676038 59.54962 \r\nL 66.958042 48.35835 \r\nL 75.240045 50.827005 \r\nL 83.522049 48.111486 \r\nL 91.804053 48.440633 \r\nL 100.086056 46.712569 \r\nL 108.36806 42.10439 \r\nL 116.650064 43.750171 \r\nL 124.932067 42.022107 \r\nL 133.214071 40.62319 \r\nL 141.496075 36.179592 \r\nL 149.778079 43.914752 \r\nL 158.060082 41.446081 \r\nL 166.342086 37.331645 \r\nL 174.62409 34.040084 \r\nL 182.906093 35.685865 \r\nL 191.188097 34.61611 \r\nL 199.470101 34.533828 \r\nL 207.752105 32.888047 \r\nL 216.034108 31.982874 \r\nL 224.316112 32.888047 \r\nL 232.598116 36.09731 \r\nL 240.880119 38.483682 \r\nL 249.162123 31.982874 \r\nL 257.444127 33.381775 \r\nL 265.726131 36.426472 \r\nL 274.008134 31.48913 \r\nL 282.290138 32.97033 \r\nL 290.572142 33.957801 \r\nL 298.854145 32.558884 \r\nL 307.136149 32.888047 \r\nL 315.418153 31.324565 \r\nL 323.700157 33.710937 \r\nL 331.98216 35.109838 \r\nL 340.264164 32.147455 \r\nL 348.546168 31.242266 \r\nL 356.828171 34.369246 \r\nL 365.110175 29.185057 \r\nL 373.392179 32.229738 \r\nL 381.674183 33.628639 \r\nL 389.956186 31.077685 \r\nL 398.23819 29.020475 \r\nL 406.520194 36.9202 \r\nL 414.802197 31.73601 \r\nL 423.084201 32.312021 \r\nL 431.366205 33.464074 \r\nL 439.648208 31.818293 \r\nL 447.930212 29.020475 \r\nL 456.212216 34.698409 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 282.799219 \r\nL 30.103125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 476.503125 282.799219 \r\nL 476.503125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 282.799219 \r\nL 476.503125 282.799219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 10.999219 \r\nL 476.503125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 37.103125 277.799219 \r\nL 134.046875 277.799219 \r\nQ 136.046875 277.799219 136.046875 275.799219 \r\nL 136.046875 217.530469 \r\nQ 136.046875 215.530469 134.046875 215.530469 \r\nL 37.103125 215.530469 \r\nQ 35.103125 215.530469 35.103125 217.530469 \r\nL 35.103125 275.799219 \r\nQ 35.103125 277.799219 37.103125 277.799219 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_29\">\r\n     <path d=\"M 39.103125 223.628906 \r\nL 59.103125 223.628906 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_30\"/>\r\n    <g id=\"text_13\">\r\n     <!-- loss -->\r\n     <g transform=\"translate(67.103125 227.128906)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_31\">\r\n     <path d=\"M 39.103125 238.307031 \r\nL 59.103125 238.307031 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_32\"/>\r\n    <g id=\"text_14\">\r\n     <!-- accuracy -->\r\n     <g transform=\"translate(67.103125 241.807031)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"61.279297\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"171.240234\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"234.619141\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"275.732422\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"337.011719\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"391.992188\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_33\">\r\n     <path d=\"M 39.103125 252.985156 \r\nL 59.103125 252.985156 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_34\"/>\r\n    <g id=\"text_15\">\r\n     <!-- val_loss -->\r\n     <g transform=\"translate(67.103125 256.485156)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 8.796875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nL 35.6875 0 \r\nL 23.484375 0 \r\nz\r\n\" id=\"DejaVuSans-118\"/>\r\n       <path d=\"M 50.984375 -16.609375 \r\nL 50.984375 -23.578125 \r\nL -0.984375 -23.578125 \r\nL -0.984375 -16.609375 \r\nz\r\n\" id=\"DejaVuSans-95\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_35\">\r\n     <path d=\"M 39.103125 267.941406 \r\nL 59.103125 267.941406 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_36\"/>\r\n    <g id=\"text_16\">\r\n     <!-- val_accuracy -->\r\n     <g transform=\"translate(67.103125 271.441406)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"259.521484\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"369.482422\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"432.861328\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"473.974609\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"535.253906\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"590.234375\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p8ae2ea1b2d\">\r\n   <rect height=\"271.8\" width=\"446.4\" x=\"30.103125\" y=\"10.999219\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1393   24    0   23   53]\n [  34  964    0   11    1]\n [   0    0    0    0    2]\n [   2    0    0  297   64]\n [  73    0    0    1  361]]\n"
     ]
    }
   ],
   "source": [
    "predictions = nonlinear_model.predict(X_dev)\n",
    "result = tf.argmax(predictions, axis=1)\n",
    "conf_mx = tf.math.confusion_matrix(y_dev, result.numpy()).numpy()\n",
    "print(conf_mx)"
   ]
  },
  {
   "source": [
    "# Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9161821705426356"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = tf.argmax(nonlinear_model.predict(X_test), axis = 1)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "source": [
    "yaay"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9174718875053544 0.9161821705426356 0.9162949929148406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 245.2025 248.518125\" width=\"245.2025pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-11-24T12:45:29.063438</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 245.2025 248.518125 \r\nL 245.2025 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 20.5625 224.64 \r\nL 238.0025 224.64 \r\nL 238.0025 7.2 \r\nL 20.5625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pb8197d368a)\">\r\n    <image height=\"218\" id=\"imagec0628ac00e\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"20.5625\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAC40lEQVR4nO3VoXVUURiF0ftYMdgYBHWkFyqghrgZXCytIPGj0gsW+Whhrvn+JOxdwTHfOsdav8/1btymB/BWvFynF2z5ND0A/gdCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAg8LDWbXoDb8W36/SC+z3/ml6wxaNBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBA41rqc0yPgo/NoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAaBh7W+Tm+42/n6fXrCluPpMj1h0+fpARv+Tg/Y4tEgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgcl7XO6RH3+rF+Tk/Y9Gd6wKbH6QEbvkwP2OLRICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0C/wAaNxEofdlIyQAAAABJRU5ErkJggg==\" y=\"-6.64\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m4fc0dec9e9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"42.3065\" xlink:href=\"#m4fc0dec9e9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(39.12525 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"85.7945\" xlink:href=\"#m4fc0dec9e9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 1 -->\r\n      <g transform=\"translate(82.61325 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"129.2825\" xlink:href=\"#m4fc0dec9e9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 2 -->\r\n      <g transform=\"translate(126.10125 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.7705\" xlink:href=\"#m4fc0dec9e9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 3 -->\r\n      <g transform=\"translate(169.58925 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"216.2585\" xlink:href=\"#m4fc0dec9e9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 4 -->\r\n      <g transform=\"translate(213.07725 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_6\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m32dc2add20\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m32dc2add20\" y=\"28.944\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(7.2 32.743219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m32dc2add20\" y=\"72.432\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 1 -->\r\n      <g transform=\"translate(7.2 76.231219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m32dc2add20\" y=\"115.92\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 2 -->\r\n      <g transform=\"translate(7.2 119.719219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m32dc2add20\" y=\"159.408\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 3 -->\r\n      <g transform=\"translate(7.2 163.207219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m32dc2add20\" y=\"202.896\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 4 -->\r\n      <g transform=\"translate(7.2 206.695219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 20.5625 224.64 \r\nL 20.5625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 238.0025 224.64 \r\nL 238.0025 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 20.5625 224.64 \r\nL 238.0025 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 20.5625 7.2 \r\nL 238.0025 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pb8197d368a\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"20.5625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.imshow(conf_mx, cmap = \"jet\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}